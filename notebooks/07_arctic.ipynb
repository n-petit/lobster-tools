{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arctic\n",
    "\n",
    "> Arctic helper scripts and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp arctic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "from string import Template\n",
    "import click\n",
    "from click.testing import CliRunner\n",
    "from arcticdb import Arctic, QueryBuilder\n",
    "from arcticdb.version_store.library import Library\n",
    "from arcticdb.exceptions import LibraryNotFound\n",
    "import hydra\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "import textwrap\n",
    "from lobster_tools.config import (\n",
    "    MainConfig,\n",
    "    Overrides,\n",
    "    NASDAQExchange,\n",
    "    ETFMembers,\n",
    "    etf_to_equities,\n",
    "    register_configs,\n",
    "    get_config,\n",
    ")\n",
    "from lobster_tools.preprocessing import Data, Lobster, MPLobster, Event, infer_ticker_to_date_range, infer_ticker_to_ticker_path, infer_ticker_dict, EhMPLobster\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from logging import Logger\n",
    "from datetime import date\n",
    "from typing import Callable, TypedDict, Protocol, NotRequired, Required, cast\n",
    "from dataclasses import dataclass, asdict\n",
    "import time\n",
    "from inspect import signature\n",
    "from functools import wraps\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, wait, as_completed\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the `@hydra.main` decorator, `register_configs` must be called. If simply using a notebook or writing the CLIs with `click`, it is enough to use `get_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "register_configs()\n",
    "cfg = get_config(overrides=Overrides.full_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "CONTEXT_SETTINGS = dict(\n",
    "    help_option_names=[\"-h\", \"--help\"],\n",
    "    token_normalize_func=lambda x: x.lower() if isinstance(x, str) else x,\n",
    "    show_default=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code had library passed to all. maybe nicer to use the context thing in the end and do sth like\n",
    "arctic --library=testa --db_path=sth NEXT_COMMAND. This maybe makes some of the decorators i had less relevant as i won't be specifying libray and db_path all over the place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor so that arctic gets Arctci() and passes that down to subcommands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class ArcticLibraryInfo:\n",
    "    ticker: str\n",
    "    dates_ndarray: np.ndarray\n",
    "    dates_series: pd.Series\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.dates_list: list[str] = list(self.dates_ndarray)\n",
    "        self.start_date = min(self.dates_ndarray)\n",
    "        self.end_date = max(self.dates_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "CONTEXT_SETTINGS = dict(\n",
    "    help_option_names=[\"-h\", \"--help\"],\n",
    "    token_normalize_func=lambda x: x.lower() if isinstance(x, str) else x,\n",
    "    show_default=True,\n",
    "    auto_envvar_prefix=\"ARCTIC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _single_write_within_multi_write(arctic_library, data):\n",
    "    lobster = Lobster(data=data)\n",
    "    df = pd.concat([lobster.messages, lobster.book], axis=1)\n",
    "    print(df.head())\n",
    "\n",
    "    arctic_library.write(symbol=data.ticker, data=df)\n",
    "    print(f\"finished writing ticker {data.ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Library' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb Cell 24\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# | export\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# REFACTORINOOOOO\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_library_info\u001b[39m(\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     arctic_library: Library,  \u001b[39m# arcticdb library\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     tickers: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,  \u001b[39m# tickers to filter on\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[ArcticLibraryInfo]:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return information about ticker info in database.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/07_arctic.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     arctic_symbols \u001b[39m=\u001b[39m arctic_library\u001b[39m.\u001b[39mlist_symbols()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Library' is not defined"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "def get_library_info(\n",
    "    arctic_library: Library,  # arcticdb library\n",
    "    tickers: list[str] | None = None,  # tickers to filter on\n",
    ") -> list[ArcticLibraryInfo]:\n",
    "    \"\"\"Return information about ticker info in database.\"\"\"\n",
    "\n",
    "    arctic_symbols = arctic_library.list_symbols()\n",
    "    if tickers:\n",
    "        if not set(tickers).issubset(set(arctic_symbols)):\n",
    "            raise ValueError(\n",
    "                f\"Some of the tickers specified were not in the databasee. The invalid tickers were {set(tickers) - set(arctic_symbols)}\"\n",
    "            )\n",
    "    else:\n",
    "        tickers = arctic_symbols\n",
    "\n",
    "    arctic_library_infos: list[ArcticLibraryInfo] = []\n",
    "    for ticker in tickers:\n",
    "        q = QueryBuilder()\n",
    "        # there is one auction each morning\n",
    "        q = q[q.event == Event.CROSS_TRADE.value]\n",
    "        df = arctic_library.read(symbol=ticker, query_builder=q).data\n",
    "\n",
    "        dates_series: pd.Series = df.index.date\n",
    "        dates_ndarray: np.ndarray = df.index.to_series().dt.strftime(\"%Y-%m-%d\").values\n",
    "        arctic_library_infos.append(\n",
    "            ArcticLibraryInfo(\n",
    "                ticker=ticker, dates_ndarray=dates_ndarray, dates_series=dates_series\n",
    "            )\n",
    "        )\n",
    "    return arctic_library_infos\n",
    "\n",
    "\n",
    "class Options:\n",
    "    def __init__(self) -> None:\n",
    "        self.db_path = click.option(\n",
    "            \"-d\", \"--db_path\", default=cfg.db.db_path, help=\"Database path\"\n",
    "        )\n",
    "        self.library = click.option(\n",
    "            \"-l\", \"--library\", default=cfg.db.library, help=\"Library name\"\n",
    "        )\n",
    "        self.ticker = click.option(\n",
    "            \"-t\", \"--ticker\", required=True, help=\"ticker to print\"\n",
    "        )\n",
    "        self.start_date = click.option(\n",
    "            \"-s\", \"--start_date\", default=None, help=\"start date\"\n",
    "        )\n",
    "        self.end_date = click.option(\"-e\", \"--end_date\", default=None, help=\"end date\")\n",
    "        self.csv_path = click.option(\n",
    "            \"-c\",\n",
    "            \"--csv_path\",\n",
    "            default=cfg.data_config.csv_files_path,\n",
    "            help=\"csv files path\",\n",
    "        )\n",
    "        self.etf = click.option(\n",
    "            \"--etf\", default=None, help=\"restrict to subset specified by ETF members\"\n",
    "        )\n",
    "        self.zip_path = click.option(\n",
    "            \"-z\",\n",
    "            \"--zip_path\",\n",
    "            default=\"/nfs/lobster_data/lobster_raw/2016\",\n",
    "            help=\"zip files path\",\n",
    "        )\n",
    "        self.tickers = click.option(\n",
    "            \"--tickers\", default=None, multiple=True, type=str, help=\"tickers to dump\"\n",
    "        )\n",
    "        self.max_workers = click.option(\n",
    "            \"-m\", \"--max_workers\", default=20, help=\"max workers for parallelisation\"\n",
    "        )\n",
    "\n",
    "\n",
    "O = Options()\n",
    "\n",
    "\n",
    "class ConsoleNotify:\n",
    "    def warn(self):\n",
    "        click.secho(\"WARNING:\", fg=\"red\", bold=True, underline=True)\n",
    "\n",
    "    def info(self):\n",
    "        click.secho(\"INFO:\", fg=\"yellow\", bold=True, underline=True)\n",
    "\n",
    "    def sucess(self):\n",
    "        click.secho(\"SUCESS\", fg=\"green\", bold=True, underline=True)\n",
    "\n",
    "\n",
    "C = ConsoleNotify()\n",
    "\n",
    "\n",
    "def apply_options(options: list):\n",
    "    def decorator(f):\n",
    "        for option in reversed(options):\n",
    "            f = option(f)\n",
    "        return f\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class ClickCtxObj(TypedDict):\n",
    "    \"Purely for type hinting. for instance `arctic_library` not always there.\"\n",
    "    library: str\n",
    "    db_path: str\n",
    "    arctic: Arctic\n",
    "    arctic_library: NotRequired[Library]\n",
    "\n",
    "\n",
    "class ClickCtx(Protocol):\n",
    "    obj: ClickCtxObj\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.argument(\"etf\")\n",
    "@click.option(\"-s\", \"--sep\", default=\"\\n\", help=\"separator\")\n",
    "def etf(etf, sep):\n",
    "    \"Output constituents of ETF including the ETF itself\"\n",
    "    click.echo(sep.join([etf] + etf_to_equities[etf]))\n",
    "\n",
    "\n",
    "@click.command()\n",
    "def pfmt():\n",
    "    \"Simple jq like utility to pretty format json objects.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "        click.echo(pformat(obj))\n",
    "\n",
    "\n",
    "@click.group(context_settings=CONTEXT_SETTINGS)\n",
    "@click.option(\n",
    "    \"-d\", \"--db_path\", default=cfg.db.db_path, envvar=\"DB_PATH\", help=\"Database path\"\n",
    ")\n",
    "@click.option(\n",
    "    \"-l\", \"--library\", default=cfg.db.library, envvar=\"LIBRARY\", help=\"Library name\"\n",
    ")\n",
    "@click.option(\"--s3\", is_flag=True, default=True, help=\"Use s3 bucket\")\n",
    "@click.pass_context\n",
    "def arctic(ctx, db_path, library, s3):\n",
    "    ctx.ensure_object(dict)\n",
    "    if s3:\n",
    "        arctic = Arctic(\n",
    "            \"s3://163.1.179.45:9100:lobster?access=minioadmin&secret=minioadmin\"\n",
    "        )\n",
    "    else:\n",
    "        arctic = Arctic(f\"lmdb://{db_path}\")\n",
    "    ctx.obj.update(\n",
    "        {\n",
    "            \"arctic\": arctic,\n",
    "            \"library\": library,\n",
    "            \"db_path\": db_path,\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        ctx.obj[\"arctic_library\"] = arctic[library]\n",
    "    except LibraryNotFound:\n",
    "        pass\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "def echo(ctx: ClickCtx) -> None:\n",
    "    \"Debugging tool that echoes back the arctic object.\"\n",
    "    click.echo(pformat(ctx.obj))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "def init():\n",
    "    \"UNTESTED. Initialise autocomplete for arctic CLI.\"\n",
    "    # NOTE: UNTESTED\n",
    "    os.system(\"_ARCTIC_COMPLETE=bash_source arctic > ~/.arctic-complete.bash\")\n",
    "\n",
    "    with open(os.path.expanduser(\"~/.bashrc\"), \"a\") as f:\n",
    "        f.write(\n",
    "            textwrap.dedent(\n",
    "                \"\"\"\\\n",
    "                # >>> arctic init_autocomplete >>>\n",
    "                # Contents within this block were generated by arctic init_autocomplete\n",
    "                . ~/.arctic-complete.bash\n",
    "                # <<< arctic init_autocomplete <<<\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    click.echo(\n",
    "        \"Autocomplete initialized. Please restart your shell or run `source ~/.bashrc`.\"\n",
    "    )\n",
    "    click.echo(\n",
    "        \"Autocomplete initialized. Please restart your shell or run `source ~/.bashrc`.\"\n",
    "    )\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "def create(ctx: ClickCtx) -> None:\n",
    "    \"\"\"Create a blank library\"\"\"\n",
    "    arctic = ctx.obj[\"arctic\"]\n",
    "    library = ctx.obj[\"library\"]\n",
    "    arctic.create_library(library)\n",
    "    click.echo(arctic[library])\n",
    "\n",
    "\n",
    "@arctic.group()\n",
    "@click.pass_context\n",
    "def ls(ctx: ClickCtx):\n",
    "    \"List information about a library\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.pass_context\n",
    "def libraries(ctx: ClickCtx):\n",
    "    arctic = ctx.obj[\"arctic\"]\n",
    "    click.echo(arctic.list_libraries())\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.pass_context\n",
    "def symbols(ctx: ClickCtx):\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "    click.echo(arctic_library.list_symbols())\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.pass_context\n",
    "def versions(ctx: ClickCtx):\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "\n",
    "    click.echo(\n",
    "        (\n",
    "            pd.DataFrame(arctic_library.list_versions())\n",
    "            .transpose()\n",
    "            .drop(columns=[1, 2])\n",
    "            .rename(columns={0: \"created_on\"})\n",
    "            .assign(\n",
    "                created_on=lambda df: df[\"created_on\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            )\n",
    "            .rename_axis([\"ticker\", \"version\"])\n",
    "            .sort_index(level=[0, 1], ascending=[True, False])\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.option(\n",
    "    \"-t\", \"--tickers\", multiple=True, type=str, help=\"Provide ticker(s) to filter on\"\n",
    ")\n",
    "@click.option(\n",
    "    \"-a\",\n",
    "    \"--all\",\n",
    "    is_flag=True,\n",
    "    default=False,\n",
    "    help=\"print all dates not just start and end\",\n",
    ")\n",
    "@click.pass_context\n",
    "def dates(ctx: ClickCtx, tickers, all):\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "\n",
    "    arctic_library_infos = get_library_info(arctic_library, tickers=tickers)\n",
    "\n",
    "    if all:\n",
    "        click.echo(pformat({x.ticker: x.dates_list for x in arctic_library_infos}))\n",
    "    else:\n",
    "        click.echo(\n",
    "            pformat(\n",
    "                {x.ticker: (x.start_date, x.end_date) for x in arctic_library_infos}\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "@arctic.group()\n",
    "@click.pass_context\n",
    "def rm(ctx: ClickCtx):\n",
    "    \"Remove.\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@rm.command()\n",
    "@click.pass_context\n",
    "def library(ctx: ClickCtx):\n",
    "    arctic = ctx.obj[\"arctic\"]\n",
    "    library = ctx.obj[\"library\"]\n",
    "\n",
    "    if not arctic.has_library(library):\n",
    "        click.echo(\"No library found to delete.\")\n",
    "    else:\n",
    "        arctic_library = arctic[library]\n",
    "        C.info()\n",
    "        click.echo(\n",
    "            textwrap.dedent(\n",
    "                f\"\"\"\\\n",
    "                Library information:\n",
    "                {arctic_library}\n",
    "\n",
    "                Tickers in this library:\n",
    "                {arctic_library.list_symbols()}\"\"\"\n",
    "            )\n",
    "        )\n",
    "        C.warn()\n",
    "\n",
    "        confirmation = click.prompt(\n",
    "            f\"Type {library} to confirm the permanent deletion of the library\"\n",
    "        )\n",
    "        if confirmation == library:\n",
    "            del ctx.obj[\"arctic_library\"]\n",
    "            del arctic_library\n",
    "            arctic.delete_library(library)\n",
    "            C.sucess()\n",
    "        else:\n",
    "            raise click.Abort()\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.argument(\"query_template\")\n",
    "def query(query_template: str):\n",
    "    \"Write a custom query using a string template. Reads json objects from stdin and writes queries to stdout.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "        query = Template(query_template).substitute(obj)\n",
    "        click.echo(query)\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.argument(\"tickers\", nargs=-1)\n",
    "def filter(tickers: tuple):\n",
    "    \"Filter by ticker. Reads json objects from stdin and writes filtered objects to stdout.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "        if obj[\"ticker\"] in tickers:\n",
    "            click.echo(json.dumps(obj))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.option(\n",
    "    \"-f\",\n",
    "    \"--files_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    help=\"files path\",\n",
    ")\n",
    "def finfo(files_path):\n",
    "    \"Output json objects with folder information.\"\n",
    "    l = infer_ticker_dict(files_path)\n",
    "    l = [asdict(x) for x in l]\n",
    "    l = [json.dumps(x) for x in l]\n",
    "    click.echo(\"\\n\".join(l))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "@click.option(\"-s\", \"--start_date\", envvar=\"ARCTIC_START_DATE\", help=\"start date\")\n",
    "@click.option(\"-e\", \"--end_date\", envvar=\"END_DATE\", help=\"end date\")\n",
    "@click.option(\n",
    "    \"-c\",\n",
    "    \"--csv_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    envvar=\"CSV_PATH\",\n",
    "    help=\"csv files path\",\n",
    ")\n",
    "@click.option(\n",
    "    \"-z\",\n",
    "    \"--zip_path\",\n",
    "    default=\"/nfs/lobster_data/lobster_raw/2016\",\n",
    "    envvar=\"ZIP_PATH\",\n",
    "    help=\"zip files path\",\n",
    ")\n",
    "def attach(ctx, start_date, end_date, csv_path, zip_path):\n",
    "    \"Add extra metadata to JSON read from stdin.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "\n",
    "        obj[\"library\"] = ctx.obj[\"library\"]\n",
    "        obj[\"db_path\"] = ctx.obj[\"db_path\"]\n",
    "        obj[\"csv_path\"] = csv_path\n",
    "        obj[\"zip_path\"] = zip_path\n",
    "\n",
    "        if start_date:\n",
    "            obj[\"start_date\"] = start_date\n",
    "        if end_date:\n",
    "            obj[\"end_date\"] = end_date\n",
    "\n",
    "        click.echo(json.dumps(obj))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "@click.option(\n",
    "    \"-c\",\n",
    "    \"--csv_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    help=\"csv files path\",\n",
    ")\n",
    "@click.option(\n",
    "    \"--ticker\",\n",
    "    required=True,\n",
    ")\n",
    "@click.option(\n",
    "    \"--start_date\",\n",
    ")\n",
    "@click.option(\n",
    "    \"--end_date\",\n",
    ")\n",
    "def single_write(\n",
    "    ctx,\n",
    "    csv_path,\n",
    "    ticker,\n",
    "    start_date,\n",
    "    end_date,\n",
    "):\n",
    "    \"\"\"Single threaded write to database for a single ticker. Useful in conjunction with arctic query.\"\"\"\n",
    "    # i guess this interface is maybe not structured the best\n",
    "    # some stuff from arctic ctx.obj some stuff for this method.\n",
    "    try:\n",
    "        arctic_library = ctx.obj[\"arctic_library\"]\n",
    "    except KeyError:\n",
    "        raise LibraryNotFound\n",
    "    # NOTE: as of now only valid if both start and end are provided\n",
    "    if bool(start_date) ^ bool(end_date):\n",
    "        raise NotImplementedError\n",
    "    date_range = (start_date, end_date) if start_date else None\n",
    "\n",
    "    data = Data(\n",
    "        directory_path=csv_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        aggregate_duplicates=False,\n",
    "    )\n",
    "    lobster = Lobster(data=data)\n",
    "    df = pd.concat([lobster.messages, lobster.book], axis=1)\n",
    "    C.info()\n",
    "    print(f\"head of ticker {ticker}\")\n",
    "    print(df.head())\n",
    "\n",
    "    arctic_library.write(symbol=ticker, data=df)\n",
    "\n",
    "    C.sucess()\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "@click.option(\n",
    "    \"-c\",\n",
    "    \"--csv_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    help=\"csv files path\",\n",
    ")\n",
    "@click.option(\n",
    "    \"--ticker\",\n",
    "    required=True,\n",
    ")\n",
    "@click.option(\"--date_range\", nargs=2, type=str)\n",
    "@click.option(\n",
    "    \"--update\", is_flag=True, default=False, help=\"use update instead of write\"\n",
    ")\n",
    "def mp_single_write(\n",
    "    ctx,\n",
    "    csv_path,\n",
    "    ticker,\n",
    "    date_range,\n",
    "    update,\n",
    "):\n",
    "    \"\"\"Multiprocessing write to database for a single ticker.\"\"\"\n",
    "    try:\n",
    "        arctic_library = ctx.obj[\"arctic_library\"]\n",
    "    except KeyError:\n",
    "        raise LibraryNotFound\n",
    "\n",
    "    data = Data(\n",
    "        directory_path=csv_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=\"both\",\n",
    "        aggregate_duplicates=False,\n",
    "    )\n",
    "    click.echo(data)\n",
    "    lobster = MPLobster(data=data)\n",
    "\n",
    "    df = pd.concat([lobster.messages, lobster.book], axis=1)\n",
    "    C.info()\n",
    "    print(f\"head of ticker {ticker}\")\n",
    "    print(df.head())\n",
    "\n",
    "    if update:\n",
    "        # for batched writes for large tickers like SPY\n",
    "        arctic_library.update(symbol=ticker, data=df)\n",
    "    else:\n",
    "        arctic_library.write(symbol=ticker, data=df)\n",
    "    C.sucess()\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "def multi_write(ctx):\n",
    "    try:\n",
    "        arctic_library = ctx.obj[\"arctic_library\"]\n",
    "    except KeyError:\n",
    "        raise LibraryNotFound\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=20) as executor:\n",
    "        futures = []\n",
    "        for line in sys.stdin:\n",
    "            obj = json.loads(line.strip())\n",
    "\n",
    "            csv_path = obj.get(\"csv_path\")\n",
    "            # db_path = obj.get(\"db_path\")\n",
    "            ticker = obj.get(\"ticker\")\n",
    "            start_date = obj.get(\"start_date\")\n",
    "            end_date = obj.get(\"end_date\")\n",
    "\n",
    "            if bool(start_date) ^ bool(end_date):\n",
    "                raise NotImplementedError\n",
    "            date_range = (start_date, end_date) if start_date else None\n",
    "\n",
    "            data = Data(\n",
    "                directory_path=csv_path,\n",
    "                ticker=ticker,\n",
    "                date_range=date_range,\n",
    "                aggregate_duplicates=False,\n",
    "            )\n",
    "\n",
    "            # executor.submit(_single_write_within_multi_write, data)\n",
    "            # future = executor.submit(demo, csv_path=csv_path, db_path=db_path, ticker=ticker, start_date=start_date, end_date=end_date)\n",
    "            future = executor.submit(\n",
    "                _single_write_within_multi_write,\n",
    "                arctic_library=arctic_library,\n",
    "                data=data,\n",
    "            )\n",
    "            futures.append(future)\n",
    "\n",
    "            for f in as_completed(futures):\n",
    "                print(f.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
