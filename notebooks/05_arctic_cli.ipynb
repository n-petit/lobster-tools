{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcticDB CLI\n",
    "\n",
    "> ArcticDB CLI tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp arctic_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "import sys\n",
    "import textwrap\n",
    "import typing as t\n",
    "from dataclasses import asdict, dataclass\n",
    "from pprint import pformat\n",
    "from string import Template\n",
    "from typing import NotRequired, Protocol\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arcticdb import Arctic, QueryBuilder\n",
    "from arcticdb.exceptions import LibraryNotFound\n",
    "from arcticdb.version_store.library import Library\n",
    "\n",
    "from lobster_tools.config import (\n",
    "    Overrides,\n",
    "    etf_to_equities,\n",
    "    get_config,\n",
    ")\n",
    "from lobster_tools.preprocessing import (\n",
    "    Data,\n",
    "    Event,\n",
    "    Lobster,\n",
    "    MPLobster,\n",
    "    infer_ticker_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "cfg = get_config(overrides=Overrides.full_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class ArcticLibraryInfo:\n",
    "    ticker: str\n",
    "    dates_ndarray: np.ndarray\n",
    "    dates_series: pd.Series\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.dates_list: list[str] = list(self.dates_ndarray)\n",
    "        self.start_date = min(self.dates_ndarray)\n",
    "        self.end_date = max(self.dates_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "CONTEXT_SETTINGS = dict(\n",
    "    help_option_names=[\"-h\", \"--help\"],\n",
    "    token_normalize_func=lambda x: x.lower() if isinstance(x, str) else x,\n",
    "    show_default=True,\n",
    "    auto_envvar_prefix=\"ARCTIC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_library_info(\n",
    "    arctic_library: Library,  # arcticdb library\n",
    "    tickers: list[str] | None = None,  # tickers to filter on\n",
    ") -> list[ArcticLibraryInfo]:\n",
    "    \"\"\"Return information about ticker info in database.\"\"\"\n",
    "\n",
    "    arctic_symbols = arctic_library.list_symbols()\n",
    "    if tickers:\n",
    "        if not set(tickers).issubset(set(arctic_symbols)):\n",
    "            raise ValueError(\n",
    "                f\"Some of the tickers specified were not in the databasee. The invalid tickers were {set(tickers) - set(arctic_symbols)}\"\n",
    "            )\n",
    "    else:\n",
    "        tickers = arctic_symbols\n",
    "\n",
    "    arctic_library_infos: list[ArcticLibraryInfo] = []\n",
    "    for ticker in tickers:\n",
    "        q = QueryBuilder()\n",
    "        # there is one auction each morning\n",
    "        q = q[q.event == Event.CROSS_TRADE.value]\n",
    "        df = arctic_library.read(symbol=ticker, query_builder=q).data\n",
    "\n",
    "        dates_series: pd.Series = df.index.date\n",
    "        dates_ndarray: np.ndarray = df.index.to_series().dt.strftime(\"%Y-%m-%d\").values\n",
    "        arctic_library_infos.append(\n",
    "            ArcticLibraryInfo(\n",
    "                ticker=ticker, dates_ndarray=dates_ndarray, dates_series=dates_series\n",
    "            )\n",
    "        )\n",
    "    return arctic_library_infos\n",
    "\n",
    "\n",
    "class Options:\n",
    "    def __init__(self) -> None:\n",
    "        self.db_path = click.option(\n",
    "            \"-d\", \"--db_path\", default=cfg.db.db_path, help=\"Database path\"\n",
    "        )\n",
    "        self.library = click.option(\n",
    "            \"-l\", \"--library\", default=cfg.db.library, help=\"Library name\"\n",
    "        )\n",
    "        self.ticker = click.option(\n",
    "            \"-t\", \"--ticker\", required=True, help=\"ticker to print\"\n",
    "        )\n",
    "        self.start_date = click.option(\n",
    "            \"-s\", \"--start_date\", default=None, help=\"start date\"\n",
    "        )\n",
    "        self.end_date = click.option(\"-e\", \"--end_date\", default=None, help=\"end date\")\n",
    "        self.csv_path = click.option(\n",
    "            \"-c\",\n",
    "            \"--csv_path\",\n",
    "            default=cfg.data_config.csv_files_path,\n",
    "            help=\"csv files path\",\n",
    "        )\n",
    "        self.etf = click.option(\n",
    "            \"--etf\", default=None, help=\"restrict to subset specified by ETF members\"\n",
    "        )\n",
    "        self.zip_path = click.option(\n",
    "            \"-z\",\n",
    "            \"--zip_path\",\n",
    "            default=\"/nfs/lobster_data/lobster_raw/2021\",\n",
    "            help=\"zip files path\",\n",
    "        )\n",
    "        self.tickers = click.option(\n",
    "            \"--tickers\", default=None, multiple=True, type=str, help=\"tickers to dump\"\n",
    "        )\n",
    "        self.max_workers = click.option(\n",
    "            \"-m\", \"--max_workers\", default=20, help=\"max workers for parallelisation\"\n",
    "        )\n",
    "\n",
    "\n",
    "O = Options()\n",
    "\n",
    "\n",
    "class ConsoleNotify:\n",
    "    def warn(self):\n",
    "        click.secho(\"WARNING:\", fg=\"red\", bold=True, underline=True)\n",
    "\n",
    "    def info(self):\n",
    "        click.secho(\"INFO:\", fg=\"yellow\", bold=True, underline=True)\n",
    "\n",
    "    def sucess(self):\n",
    "        click.secho(\"SUCESS\", fg=\"green\", bold=True, underline=True)\n",
    "\n",
    "\n",
    "C = ConsoleNotify()\n",
    "\n",
    "\n",
    "def apply_options(options: list):\n",
    "    def decorator(f):\n",
    "        for option in reversed(options):\n",
    "            f = option(f)\n",
    "        return f\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class ClickCtxObj(t.TypedDict):\n",
    "    \"Purely for type hinting. for instance `arctic_library` not always there.\"\n",
    "\n",
    "    library: str\n",
    "    db_path: str\n",
    "    arctic: Arctic\n",
    "    arctic_library: NotRequired[Library]\n",
    "\n",
    "\n",
    "class ClickCtx(Protocol):\n",
    "    obj: ClickCtxObj\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.argument(\"etf\")\n",
    "@click.option(\"-s\", \"--sep\", default=\"\\n\", help=\"separator\")\n",
    "def etf(etf, sep):\n",
    "    \"Output constituents of ETF including the ETF itself\"\n",
    "    click.echo(sep.join([etf] + etf_to_equities[etf]))\n",
    "\n",
    "\n",
    "@click.command()\n",
    "def pfmt():\n",
    "    \"Simple jq like utility to pretty format json objects.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "        click.echo(pformat(obj))\n",
    "\n",
    "\n",
    "@click.group(context_settings=CONTEXT_SETTINGS)\n",
    "@click.option(\n",
    "    \"-d\", \"--db_path\", default=cfg.db.db_path, envvar=\"DB_PATH\", help=\"Database path\"\n",
    ")\n",
    "@click.option(\n",
    "    \"-l\", \"--library\", default=cfg.db.library, envvar=\"LIBRARY\", help=\"Library name\"\n",
    ")\n",
    "@click.option(\"--s3\", is_flag=True, default=True, help=\"Use s3 bucket\")\n",
    "@click.pass_context\n",
    "def arctic(ctx, db_path, library, s3):\n",
    "    ctx.ensure_object(dict)\n",
    "    if s3:\n",
    "        arctic = Arctic(\n",
    "            \"s3://163.1.179.45:9100:lobster?access=minioadmin&secret=minioadmin\"\n",
    "        )\n",
    "    else:\n",
    "        arctic = Arctic(f\"lmdb://{db_path}\")\n",
    "    ctx.obj.update(\n",
    "        {\n",
    "            \"arctic\": arctic,\n",
    "            \"library\": library,\n",
    "            \"db_path\": db_path,\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        ctx.obj[\"arctic_library\"] = arctic[library]\n",
    "    except LibraryNotFound:\n",
    "        pass\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "def echo(ctx: ClickCtx) -> None:\n",
    "    \"Debugging tool that echoes back the arctic object.\"\n",
    "    click.echo(pformat(ctx.obj))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "def create(ctx: ClickCtx) -> None:\n",
    "    \"\"\"Create a blank library\"\"\"\n",
    "    arctic = ctx.obj[\"arctic\"]\n",
    "    library = ctx.obj[\"library\"]\n",
    "    arctic.create_library(library)\n",
    "    click.echo(arctic[library])\n",
    "\n",
    "\n",
    "@arctic.group()\n",
    "@click.pass_context\n",
    "def ls(ctx: ClickCtx):\n",
    "    \"List information about a library\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.pass_context\n",
    "def libraries(ctx: ClickCtx):\n",
    "    arctic = ctx.obj[\"arctic\"]\n",
    "    click.echo(arctic.list_libraries())\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.pass_context\n",
    "def symbols(ctx: ClickCtx):\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "    click.echo(arctic_library.list_symbols())\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.pass_context\n",
    "def versions(ctx: ClickCtx):\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "\n",
    "    click.echo(\n",
    "        (\n",
    "            pd.DataFrame(arctic_library.list_versions())\n",
    "            .transpose()\n",
    "            .drop(columns=[1, 2])\n",
    "            .rename(columns={0: \"created_on\"})\n",
    "            .assign(\n",
    "                created_on=lambda df: df[\"created_on\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            )\n",
    "            .rename_axis([\"ticker\", \"version\"])\n",
    "            .sort_index(level=[0, 1], ascending=[True, False])\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "@ls.command()\n",
    "@click.option(\n",
    "    \"-t\", \"--tickers\", multiple=True, type=str, help=\"Provide ticker(s) to filter on\"\n",
    ")\n",
    "@click.option(\n",
    "    \"-a\",\n",
    "    \"--all\",\n",
    "    is_flag=True,\n",
    "    default=False,\n",
    "    help=\"print all dates not just start and end\",\n",
    ")\n",
    "@click.pass_context\n",
    "def dates(ctx: ClickCtx, tickers, all):\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "\n",
    "    arctic_library_infos = get_library_info(arctic_library, tickers=tickers)\n",
    "\n",
    "    if all:\n",
    "        click.echo(pformat({x.ticker: x.dates_list for x in arctic_library_infos}))\n",
    "    else:\n",
    "        click.echo(\n",
    "            pformat(\n",
    "                {x.ticker: (x.start_date, x.end_date) for x in arctic_library_infos}\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "@arctic.group()\n",
    "@click.pass_context\n",
    "def rm(ctx: ClickCtx):\n",
    "    \"Remove.\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@rm.command()\n",
    "@click.pass_context\n",
    "def library(ctx: ClickCtx):\n",
    "    arctic = ctx.obj[\"arctic\"]\n",
    "    library = ctx.obj[\"library\"]\n",
    "\n",
    "    if not arctic.has_library(library):\n",
    "        click.echo(\"No library found to delete.\")\n",
    "    else:\n",
    "        arctic_library = arctic[library]\n",
    "        C.info()\n",
    "        click.echo(\n",
    "            textwrap.dedent(\n",
    "                f\"\"\"\\\n",
    "                Library information:\n",
    "                {arctic_library}\n",
    "\n",
    "                Tickers in this library:\n",
    "                {arctic_library.list_symbols()}\"\"\"\n",
    "            )\n",
    "        )\n",
    "        C.warn()\n",
    "\n",
    "        confirmation = click.prompt(\n",
    "            f\"Type {library} to confirm the permanent deletion of the library\"\n",
    "        )\n",
    "        if confirmation == library:\n",
    "            del ctx.obj[\"arctic_library\"]\n",
    "            del arctic_library\n",
    "            arctic.delete_library(library)\n",
    "            C.sucess()\n",
    "        else:\n",
    "            raise click.Abort()\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.argument(\"query_template\")\n",
    "def query(query_template: str):\n",
    "    \"Write a custom query using a string template. Reads json objects from stdin and writes queries to stdout.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "        query = Template(query_template).substitute(obj)\n",
    "        click.echo(query)\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.argument(\"tickers\", nargs=-1)\n",
    "def filter(tickers: tuple):\n",
    "    \"Filter by ticker. Reads json objects from stdin and writes filtered objects to stdout.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "        if obj[\"ticker\"] in tickers:\n",
    "            click.echo(json.dumps(obj))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.option(\n",
    "    \"-f\",\n",
    "    \"--files_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    help=\"files path\",\n",
    ")\n",
    "def finfo(files_path):\n",
    "    \"Output json objects with folder information.\"\n",
    "    l = infer_ticker_dict(files_path)\n",
    "    l = [asdict(x) for x in l]\n",
    "    l = [json.dumps(x) for x in l]\n",
    "    click.echo(\"\\n\".join(l))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "@click.option(\"-s\", \"--start_date\", envvar=\"ARCTIC_START_DATE\", help=\"start date\")\n",
    "@click.option(\"-e\", \"--end_date\", envvar=\"END_DATE\", help=\"end date\")\n",
    "@click.option(\n",
    "    \"-c\",\n",
    "    \"--csv_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    envvar=\"CSV_PATH\",\n",
    "    help=\"csv files path\",\n",
    ")\n",
    "@click.option(\n",
    "    \"-z\",\n",
    "    \"--zip_path\",\n",
    "    default=\"/nfs/lobster_data/lobster_raw/2021\",\n",
    "    envvar=\"ZIP_PATH\",\n",
    "    help=\"zip files path\",\n",
    ")\n",
    "def attach(ctx, start_date, end_date, csv_path, zip_path):\n",
    "    \"Attach extra matadata to JSON objects read from stdin.\"\n",
    "    for line in sys.stdin:\n",
    "        obj = json.loads(line.strip())\n",
    "\n",
    "        obj[\"library\"] = ctx.obj[\"library\"]\n",
    "        obj[\"db_path\"] = ctx.obj[\"db_path\"]\n",
    "        obj[\"csv_path\"] = csv_path\n",
    "        obj[\"zip_path\"] = zip_path\n",
    "\n",
    "        if start_date:\n",
    "            obj[\"start_date\"] = start_date\n",
    "        if end_date:\n",
    "            obj[\"end_date\"] = end_date\n",
    "\n",
    "        click.echo(json.dumps(obj))\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "@click.option(\n",
    "    \"-z\",\n",
    "    \"--zip_path\",\n",
    "    default=\"/nfs/lobster_data/lobster_raw/2021\",\n",
    "    help=\"zip files path\",\n",
    ")\n",
    "def diff(\n",
    "    ctx: ClickCtx,\n",
    "    zip_path: str,\n",
    "):\n",
    "    \"Tickers still to be written to database.\"\n",
    "    arctic_library = ctx.obj[\"arctic_library\"]\n",
    "\n",
    "    csv_info = infer_ticker_dict(zip_path)\n",
    "    csv_tickers = [x.ticker for x in csv_info]\n",
    "\n",
    "    arctic_tickers = arctic_library.list_symbols()\n",
    "\n",
    "    tickers_difference = set(csv_tickers).difference(arctic_tickers)\n",
    "    click.echo(tickers_difference)\n",
    "\n",
    "\n",
    "@arctic.command()\n",
    "@click.pass_context\n",
    "@click.option(\n",
    "    \"-c\",\n",
    "    \"--csv_path\",\n",
    "    default=cfg.data_config.csv_files_path,\n",
    "    help=\"csv files path\",\n",
    ")\n",
    "@click.option(\n",
    "    \"--ticker\",\n",
    "    required=True,\n",
    ")\n",
    "@click.option(\"--date_range\", nargs=2, type=str)\n",
    "@click.option(\n",
    "    \"--update\", is_flag=True, default=False, help=\"use update instead of write\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--mp\",\n",
    "    is_flag=True,\n",
    "    default=True,\n",
    "    help=\"Use multiprocessing to load data.\",\n",
    ")\n",
    "def single_write(\n",
    "    ctx: ClickCtx,\n",
    "    csv_path: str,\n",
    "    ticker: str,\n",
    "    date_range: tuple,\n",
    "    update: bool,\n",
    "    mp: bool,\n",
    "):\n",
    "    \"\"\"Write single ticker to database.\"\"\"\n",
    "    try:\n",
    "        arctic_library = ctx.obj[\"arctic_library\"]\n",
    "    except KeyError:\n",
    "        raise LibraryNotFound\n",
    "\n",
    "    data = Data(\n",
    "        directory_path=csv_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=\"both\",\n",
    "        aggregate_duplicates=False,\n",
    "    )\n",
    "    click.echo(data)\n",
    "\n",
    "    if mp:\n",
    "        lobster = MPLobster(data=data)\n",
    "    else:\n",
    "        lobster = Lobster(data=data)\n",
    "\n",
    "    df = pd.concat([lobster.messages, lobster.book], axis=1)\n",
    "    C.info()\n",
    "    print(f\"head of ticker {ticker}\")\n",
    "    print(df.head())\n",
    "\n",
    "    if update:\n",
    "        # for batched writes for large tickers like SPY\n",
    "        arctic_library.update(symbol=ticker, data=df)\n",
    "    else:\n",
    "        arctic_library.write(symbol=ticker, data=df)\n",
    "    C.sucess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
