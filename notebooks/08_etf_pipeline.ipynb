{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETF Pipeline\n",
    "\n",
    "> ETF flow decompositions pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp etf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "\n",
    "import click\n",
    "from arcticdb import Arctic, LibraryOptions\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from lobster_tools.config import MainConfig, register_configs\n",
    "from lobster_tools.preprocessing import *\n",
    "from lobster_tools.querying import *\n",
    "from lobster_tools.flow_decomposition import *\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import product\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "import json\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# access config by normal python import\n",
    "cfg = MainConfig()\n",
    "cfg.universe.equities\n",
    "# register configs and then build object\n",
    "register_configs()\n",
    "with initialize(version_base=None, config_path=None):\n",
    "    cfg_omega = compose(config_name=\"config\")\n",
    "    cfg = OmegaConf.to_object(compose(config_name=\"config\"))\n",
    "    print(cfg)\n",
    "    print(cfg.universe.equities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note to self\n",
    "the stuff with env variables might be good to set for stuff like clip times and all the other options. could set to None as default and look at env variable. and in the function call to get env variable you can provide a default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_environment_variables() -> None:\n",
    "#     os.environ[\"LOBSTER_DATA_PATH\"] = \"/nfs/home/nicolasp/home/data/tmp\"\n",
    "#     os.environ[\"DEFAULT_TICKER\"] = \"OKE\"\n",
    "\n",
    "# set_environment_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO write function to pop stuff into global namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = cfg.data_config.csv_files_path\n",
    "etfs = cfg.universe.etfs\n",
    "equities = cfg.universe.equities\n",
    "date_range = cfg.data_config.date_range\n",
    "markouts = cfg.hyperparameters.markouts\n",
    "finest_resample = cfg.hyperparameters.finest_resample\n",
    "max_markout = cfg.hyperparameters.max_markout\n",
    "\n",
    "load: Literal[\"both\", \"messages\", \"book\"] = \"both\"\n",
    "clip_trading_hours = True\n",
    "add_ticker_column = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/home/petit/Documents/data/lobster/csv\"\n",
    "ticker = \"AIG\"\n",
    "date_range = (\"2019-01-02\", \"2019-01-02\")\n",
    "etfs = [\"SPY\"]\n",
    "equities = ['GE', 'AIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Data.__init__.__defaults__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this soon\n",
    "# it still gets confused\n",
    "load: Literal[\"both\", \"messages\", \"book\"] = \"both\"\n",
    "class Data(Data):\n",
    "    def __init__(   self, \n",
    "                    ticker=ticker, \n",
    "                    date_range=date_range,\n",
    "                    directory_path=directory_path,\n",
    "                    load: Literal[\"both\", \"messages\", \"book\"]=load,\n",
    "                    # load=load, # type checker is confused by this. which i guess is fair enough?\n",
    "                    *args, \n",
    "                    **kwargs):\n",
    "        super().__init__(\n",
    "                    ticker=ticker, \n",
    "                    date_range=date_range,\n",
    "                    directory_path=directory_path,\n",
    "                    load=load,\n",
    "                    *args, \n",
    "                    **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = partial(Data, \n",
    "                    ticker=\"GEd\", \n",
    "                    date_range=date_range,\n",
    "                    directory_path=directory_path,\n",
    "                    load=load,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_data = Data(directory_path=directory_path,\n",
    "                   ticker=\"AIG\",\n",
    "                   date_range=date_range,\n",
    "                   load=load,\n",
    "                   clip_trading_hours=clip_trading_hours,\n",
    "                   add_ticker_column=add_ticker_column)\n",
    "\n",
    "equity_lobsters = Lobster(equity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_data = [\n",
    "    Data(\n",
    "        directory_path=directory_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=load,\n",
    "        clip_trading_hours=clip_trading_hours,\n",
    "        add_ticker_column=add_ticker_column,\n",
    "    )\n",
    "    for ticker in equities\n",
    "]\n",
    "\n",
    "equity_lobsters = [Lobster(data) for data in equity_data]\n",
    "\n",
    "equity_executions = pd.concat([lobster.messages.pipe(get_executions) for lobster in equity_lobsters])\n",
    "equity_executions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_data = [\n",
    "    Data(\n",
    "        directory_path=directory_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=load,\n",
    "        clip_trading_hours=clip_trading_hours,\n",
    "        add_ticker_column=add_ticker_column,\n",
    "    )\n",
    "    for ticker in etfs\n",
    "]\n",
    "\n",
    "etf_lobsters = [Lobster(data) for data in etf_data]\n",
    "\n",
    "etf_executions = pd.concat([lobster.messages.pipe(get_executions) for lobster in etf_lobsters])\n",
    "etf_executions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: pickle and load pickles.. looks like nbdev doesn't work with cell magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "%store etf_executions\n",
    "%store equity_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: true\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "ofi_all = ofi(etf_executions, resample_freq=\"5T\", suffix=\"all\")\n",
    "ofi_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "markout_times = markout_returns(ofi_all, markouts=markouts)\n",
    "markout_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "markout_times = markout_returns(ofi_all, markouts=markouts)\n",
    "mids = [resample_mid(lobster.book, resample_freq=finest_resample).rename(lobster.data.ticker) for lobster in etf_lobsters]\n",
    "mids = pd.concat(mids, axis=1)\n",
    "mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def compute_returns():\n",
    "    index = clip_for_markout(etf_executions.resample(resample_freq, label=\"right\").last(), max_markout=max_markout).index\n",
    "\n",
    "    returns = {}\n",
    "    for ticker in etfs:\n",
    "        df = pd.DataFrame(index=index)\n",
    "        for markout in [\"0S\"] + markouts:\n",
    "            df[f\"_{markout}\"] = mids.loc[df.index + pd.Timedelta(markout), ticker].values\n",
    "\n",
    "        for markout in markouts:\n",
    "            df.eval(f\"return_{markout} = (_{markout} / _0S ) - 1\", inplace=True)\n",
    "\n",
    "        df[\"return_contemp\"] = mids[ticker].resample(\"5T\").first().pct_change()\n",
    "        df_returns = df.filter(regex=\"return\")\n",
    "        df_returns.columns = [column.replace(\"return_\", \"\") for column in df_returns.columns]\n",
    "        df_returns.columns = [(\"_\" + column if column[0].isdigit() else column) for column in df_returns.columns ]\n",
    "        returns[ticker] = df_returns\n",
    "    return returns\n",
    "\n",
    "returns = compute_returns()\n",
    "returns[etfs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def regression_table(\n",
    "    X: pd.DataFrame,  # covariates. in this case, OFI for a single ETF\n",
    "    y: pd.DataFrame,  # response variable. in this case, mid to mid returns at various markouts\n",
    "):\n",
    "    \"\"\"Compute X.len * y.len univariate regressions. For each column in X, regress against each one column of y.\"\"\"\n",
    "    X, y = restrict_common_index(X, y)\n",
    "    \n",
    "    regression_results = []\n",
    "\n",
    "    for x_col_name, y_col_name in product(X.columns, y.columns):\n",
    "        x_col = X[x_col_name].values.reshape(-1, 1)\n",
    "        y_col = y[y_col_name].values\n",
    "        \n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(x_col, y_col)\n",
    "\n",
    "        intercept = model.intercept_\n",
    "        coefficient = model.coef_[0]\n",
    "        r2 = model.score(x_col, y_col)\n",
    "\n",
    "        regression_results.append(\n",
    "            {\n",
    "                \"id\": x_col_name + \"_\" + y_col_name,\n",
    "                \"intercept\": intercept,\n",
    "                \"coefficient\": coefficient,\n",
    "                \"r2\": r2,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    regression_results_df = pd.DataFrame(regression_results)\n",
    "    regression_results_df.set_index(\"id\", inplace=True)\n",
    "    return regression_results_df\n",
    "\n",
    "regression_table(ofi_all, returns[etfs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "drop_all_neighbor_cols(etf_executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_neighbors = add_neighbors(etf_executions=etf_executions, equity_executions=equity_executions, tolerance=tolerances)\n",
    "etf_executions_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def compute_neighbor_statistics(etf_executions_neighbors: pd.DataFrame):\n",
    "    neighbor_statistics = etf_executions_neighbors.filter(regex=\"^_\").notna().sum() / len(etf_executions_neighbors)\n",
    "    return neighbor_statistics\n",
    "\n",
    "neighbor_statistics = compute_neighbor_statistics(etf_executions_neighbors)\n",
    "pd.DataFrame({'has_neighbor':neighbor_statistics}).style.format(\"{:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_features = append_features(etf_executions=etf_executions_neighbors, equity_executions=equity_executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store etf_executions_neighbors\n",
    "%store etf_executions_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_executions_features = marginalise(etf_executions_features, over='same_sign/opposite_sign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_executions_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_executions_features[\"_500us_num_trades\"] = etf_executions_features._500us_num_trades_os_af + etf_executions_features._500us_num_trades_os_bf + etf_executions_features._500us_num_trades_ss_af + etf_executions_features._500us_num_trades_ss_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_execution_features.filter(regex=\"^_\").hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
