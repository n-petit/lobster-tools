{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETF Pipeline\n",
    "\n",
    "> ETF flow decompositions pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp etf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "\n",
    "import click\n",
    "from arcticdb import Arctic, LibraryOptions\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from lobster_tools.config import MainConfig, register_configs\n",
    "from lobster_tools.preprocessing import *\n",
    "from lobster_tools.querying import *\n",
    "from lobster_tools.flow_decomposition import *\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import product\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainConfig(hydra=CustomHydraConf(defaults=[{'output': 'default'}, {'launcher': 'basic'}, {'sweeper': 'basic'}, {'help': 'default'}, {'hydra_help': 'default'}, {'hydra_logging': 'default'}, {'job_logging': 'default'}, {'callbacks': None}, {'env': 'default'}], mode=None, searchpath=[], run=RunDir(dir='../custom_directory/${now:%Y-%m-%d}/${now:%H-%M-%S}'), sweep=SweepDir(dir='???', subdir='???'), hydra_logging='???', job_logging='???', sweeper='???', launcher='???', callbacks={}, help=HelpConf(app_name='???', header='???', footer='???', template='???'), hydra_help=HydraHelpConf(hydra_help='???', template='???'), output_subdir='.hydra', overrides=OverridesConf(hydra=[], task=[]), job=JobConf(name='???', chdir=None, override_dirname='???', id='???', num='???', config_name='???', env_set={}, env_copy=[], config=JobConf.JobConfig(override_dirname=JobConf.JobConfig.OverrideDirname(kv_sep='=', item_sep=',', exclude_keys=[]))), runtime=RuntimeConf(version='???', version_base='???', cwd='???', config_sources='???', output_dir='???', choices={}), verbose=False), db=ArcticDB(db_path='/nfs/home/nicolasp/home/data/arctic', library_name='lobster', columns_per_segment=63), data_paths=DataPaths(zip_files_path='/nfs/lobster_data/lobster_raw', csv_files_path='/nfs/home/nicolasp/home/data/tmp'), universe=Universe(etfs=['XLE']), sample_data=SampleData(ticker='AMZN', levels='5'), hyperparameters=Hyperparameters(date_range=['2020-01-02', '2020-01-02'], tolerances=['150us', '250us', '500us'], resample_freq='5min', markouts=['30S', '1min', '2min', '5min']))\n",
      "['XOM', 'CVX', 'EOG', 'COP', 'SLB', 'MPC', 'PXD', 'PSX', 'VLO', 'OXY', 'HES', 'WMB', 'KMI', 'DVN', 'BKR', 'HAL', 'OKE', 'FANG', 'CTRA', 'TRGP', 'MRO', 'EQT', 'APA']\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "# access config by normal python import\n",
    "cfg = MainConfig()\n",
    "# register configs and then build object\n",
    "register_configs()\n",
    "with initialize(version_base=None, config_path=None):\n",
    "    cfg_omega = compose(config_name=\"config\")\n",
    "    cfg = OmegaConf.to_object(compose(config_name=\"config\"))\n",
    "    print(cfg)\n",
    "    print(cfg.universe.equities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note to self\n",
    "the stuff with env variables might be good to set for stuff like clip times and all the other options. could set to None as default and look at env variable. and in the function call to get env variable you can provide a default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_environment_variables() -> None:\n",
    "#     os.environ[\"LOBSTER_DATA_PATH\"] = \"/nfs/home/nicolasp/home/data/tmp\"\n",
    "#     os.environ[\"DEFAULT_TICKER\"] = \"OKE\"\n",
    "\n",
    "# set_environment_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = cfg.data_paths.csv_files_path\n",
    "etfs = cfg.universe.etfs\n",
    "equities = cfg.universe.equities\n",
    "date_range = cfg.hyperparameters.date_range\n",
    "markouts = cfg.hyperparameters.markouts\n",
    "finest_resample = cfg.hyperparameters.finest_resample\n",
    "max_markout = cfg.hyperparameters.max_markout\n",
    "\n",
    "load = \"both\"\n",
    "clip_trading_hours = True\n",
    "add_ticker_column = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/home/petit/Documents/data/lobster/csv\"\n",
    "ticker = \"AIG\"\n",
    "date_range = (\"2019-01-02\", \"2019-01-02\")\n",
    "etfs = [\"SPY\"]\n",
    "equities = ['GE', 'AIG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_data = Data(directory_path=directory_path,\n",
    "                   ticker=\"AIG\",\n",
    "                   date_range=date_range,\n",
    "                   load=load,\n",
    "                   clip_trading_hours=clip_trading_hours,\n",
    "                   add_ticker_column=add_ticker_column)\n",
    "\n",
    "equity_lobsters = Lobster(equity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_data = [\n",
    "    Data(\n",
    "        directory_path=directory_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=load,\n",
    "        clip_trading_hours=clip_trading_hours,\n",
    "        add_ticker_column=add_ticker_column,\n",
    "    )\n",
    "    for ticker in equities\n",
    "]\n",
    "\n",
    "equity_lobsters = [Lobster(data) for data in equity_data]\n",
    "\n",
    "equity_executions = pd.concat([lobster.messages.pipe(get_executions) for lobster in equity_lobsters])\n",
    "equity_executions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_data = [\n",
    "    Data(\n",
    "        directory_path=directory_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=load,\n",
    "        clip_trading_hours=clip_trading_hours,\n",
    "        add_ticker_column=add_ticker_column,\n",
    "    )\n",
    "    for ticker in etfs\n",
    "]\n",
    "\n",
    "etf_lobsters = [Lobster(data) for data in etf_data]\n",
    "\n",
    "etf_executions = pd.concat([lobster.messages.pipe(get_executions) for lobster in etf_lobsters])\n",
    "etf_executions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "%store etf_executions\n",
    "%store equity_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: true\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_SPY_5T_ofi_all</th>\n",
       "      <th>_GE_5T_ofi_all</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:35:00</th>\n",
       "      <td>0.123398</td>\n",
       "      <td>0.108859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:40:00</th>\n",
       "      <td>0.118186</td>\n",
       "      <td>0.068916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:45:00</th>\n",
       "      <td>0.074114</td>\n",
       "      <td>-0.037293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:50:00</th>\n",
       "      <td>0.065886</td>\n",
       "      <td>-0.113141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:55:00</th>\n",
       "      <td>0.240658</td>\n",
       "      <td>-0.165625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:40:00</th>\n",
       "      <td>0.304968</td>\n",
       "      <td>-0.313950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:45:00</th>\n",
       "      <td>0.224770</td>\n",
       "      <td>-0.297484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:50:00</th>\n",
       "      <td>-0.039497</td>\n",
       "      <td>-0.283260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:55:00</th>\n",
       "      <td>0.071907</td>\n",
       "      <td>0.235449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 16:00:00</th>\n",
       "      <td>0.124430</td>\n",
       "      <td>-0.126141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _SPY_5T_ofi_all  _GE_5T_ofi_all\n",
       "datetime                                            \n",
       "2019-01-02 09:35:00         0.123398        0.108859\n",
       "2019-01-02 09:40:00         0.118186        0.068916\n",
       "2019-01-02 09:45:00         0.074114       -0.037293\n",
       "2019-01-02 09:50:00         0.065886       -0.113141\n",
       "2019-01-02 09:55:00         0.240658       -0.165625\n",
       "...                              ...             ...\n",
       "2019-01-02 15:40:00         0.304968       -0.313950\n",
       "2019-01-02 15:45:00         0.224770       -0.297484\n",
       "2019-01-02 15:50:00        -0.039497       -0.283260\n",
       "2019-01-02 15:55:00         0.071907        0.235449\n",
       "2019-01-02 16:00:00         0.124430       -0.126141\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval: false\n",
    "ofi_all = ofi(etf_executions, resample_freq=\"5T\", suffix=\"all\")\n",
    "ofi_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_30S</th>\n",
       "      <th>_1min</th>\n",
       "      <th>_2min</th>\n",
       "      <th>_5min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:35:00</th>\n",
       "      <td>2019-01-02 09:35:30</td>\n",
       "      <td>2019-01-02 09:36:00</td>\n",
       "      <td>2019-01-02 09:37:00</td>\n",
       "      <td>2019-01-02 09:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:40:00</th>\n",
       "      <td>2019-01-02 09:40:30</td>\n",
       "      <td>2019-01-02 09:41:00</td>\n",
       "      <td>2019-01-02 09:42:00</td>\n",
       "      <td>2019-01-02 09:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:45:00</th>\n",
       "      <td>2019-01-02 09:45:30</td>\n",
       "      <td>2019-01-02 09:46:00</td>\n",
       "      <td>2019-01-02 09:47:00</td>\n",
       "      <td>2019-01-02 09:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:50:00</th>\n",
       "      <td>2019-01-02 09:50:30</td>\n",
       "      <td>2019-01-02 09:51:00</td>\n",
       "      <td>2019-01-02 09:52:00</td>\n",
       "      <td>2019-01-02 09:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:55:00</th>\n",
       "      <td>2019-01-02 09:55:30</td>\n",
       "      <td>2019-01-02 09:56:00</td>\n",
       "      <td>2019-01-02 09:57:00</td>\n",
       "      <td>2019-01-02 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:40:00</th>\n",
       "      <td>2019-01-02 15:40:30</td>\n",
       "      <td>2019-01-02 15:41:00</td>\n",
       "      <td>2019-01-02 15:42:00</td>\n",
       "      <td>2019-01-02 15:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:45:00</th>\n",
       "      <td>2019-01-02 15:45:30</td>\n",
       "      <td>2019-01-02 15:46:00</td>\n",
       "      <td>2019-01-02 15:47:00</td>\n",
       "      <td>2019-01-02 15:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:50:00</th>\n",
       "      <td>2019-01-02 15:50:30</td>\n",
       "      <td>2019-01-02 15:51:00</td>\n",
       "      <td>2019-01-02 15:52:00</td>\n",
       "      <td>2019-01-02 15:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:55:00</th>\n",
       "      <td>2019-01-02 15:55:30</td>\n",
       "      <td>2019-01-02 15:56:00</td>\n",
       "      <td>2019-01-02 15:57:00</td>\n",
       "      <td>2019-01-02 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 16:00:00</th>\n",
       "      <td>2019-01-02 16:00:30</td>\n",
       "      <td>2019-01-02 16:01:00</td>\n",
       "      <td>2019-01-02 16:02:00</td>\n",
       "      <td>2019-01-02 16:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   _30S               _1min  \\\n",
       "datetime                                                      \n",
       "2019-01-02 09:35:00 2019-01-02 09:35:30 2019-01-02 09:36:00   \n",
       "2019-01-02 09:40:00 2019-01-02 09:40:30 2019-01-02 09:41:00   \n",
       "2019-01-02 09:45:00 2019-01-02 09:45:30 2019-01-02 09:46:00   \n",
       "2019-01-02 09:50:00 2019-01-02 09:50:30 2019-01-02 09:51:00   \n",
       "2019-01-02 09:55:00 2019-01-02 09:55:30 2019-01-02 09:56:00   \n",
       "...                                 ...                 ...   \n",
       "2019-01-02 15:40:00 2019-01-02 15:40:30 2019-01-02 15:41:00   \n",
       "2019-01-02 15:45:00 2019-01-02 15:45:30 2019-01-02 15:46:00   \n",
       "2019-01-02 15:50:00 2019-01-02 15:50:30 2019-01-02 15:51:00   \n",
       "2019-01-02 15:55:00 2019-01-02 15:55:30 2019-01-02 15:56:00   \n",
       "2019-01-02 16:00:00 2019-01-02 16:00:30 2019-01-02 16:01:00   \n",
       "\n",
       "                                  _2min               _5min  \n",
       "datetime                                                     \n",
       "2019-01-02 09:35:00 2019-01-02 09:37:00 2019-01-02 09:40:00  \n",
       "2019-01-02 09:40:00 2019-01-02 09:42:00 2019-01-02 09:45:00  \n",
       "2019-01-02 09:45:00 2019-01-02 09:47:00 2019-01-02 09:50:00  \n",
       "2019-01-02 09:50:00 2019-01-02 09:52:00 2019-01-02 09:55:00  \n",
       "2019-01-02 09:55:00 2019-01-02 09:57:00 2019-01-02 10:00:00  \n",
       "...                                 ...                 ...  \n",
       "2019-01-02 15:40:00 2019-01-02 15:42:00 2019-01-02 15:45:00  \n",
       "2019-01-02 15:45:00 2019-01-02 15:47:00 2019-01-02 15:50:00  \n",
       "2019-01-02 15:50:00 2019-01-02 15:52:00 2019-01-02 15:55:00  \n",
       "2019-01-02 15:55:00 2019-01-02 15:57:00 2019-01-02 16:00:00  \n",
       "2019-01-02 16:00:00 2019-01-02 16:02:00 2019-01-02 16:05:00  \n",
       "\n",
       "[78 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval: false\n",
    "markout_times = markout_returns(ofi_all, markouts=markouts)\n",
    "markout_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>GE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:30:30</th>\n",
       "      <td>246.060</td>\n",
       "      <td>7.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:31:00</th>\n",
       "      <td>246.125</td>\n",
       "      <td>7.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:31:30</th>\n",
       "      <td>246.510</td>\n",
       "      <td>7.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:32:00</th>\n",
       "      <td>246.515</td>\n",
       "      <td>7.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:32:30</th>\n",
       "      <td>246.520</td>\n",
       "      <td>7.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:58:00</th>\n",
       "      <td>250.070</td>\n",
       "      <td>8.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:58:30</th>\n",
       "      <td>250.005</td>\n",
       "      <td>8.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:59:00</th>\n",
       "      <td>249.895</td>\n",
       "      <td>8.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 15:59:30</th>\n",
       "      <td>250.115</td>\n",
       "      <td>8.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 16:00:00</th>\n",
       "      <td>250.255</td>\n",
       "      <td>8.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SPY     GE\n",
       "datetime                           \n",
       "2019-01-02 09:30:30  246.060  7.445\n",
       "2019-01-02 09:31:00  246.125  7.465\n",
       "2019-01-02 09:31:30  246.510  7.455\n",
       "2019-01-02 09:32:00  246.515  7.455\n",
       "2019-01-02 09:32:30  246.520  7.445\n",
       "...                      ...    ...\n",
       "2019-01-02 15:58:00  250.070  8.035\n",
       "2019-01-02 15:58:30  250.005  8.025\n",
       "2019-01-02 15:59:00  249.895  8.025\n",
       "2019-01-02 15:59:30  250.115  8.035\n",
       "2019-01-02 16:00:00  250.255  8.045\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval: false\n",
    "markout_times = markout_returns(ofi_all, markouts=markouts)\n",
    "mids = [resample_mid(lobster.book, resample_freq=finest_resample).rename(lobster.data.ticker) for lobster in etf_lobsters]\n",
    "mids = pd.concat(mids, axis=1)\n",
    "mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip_times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         returns[ticker] \u001b[39m=\u001b[39m df_returns\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m returns\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m returns \u001b[39m=\u001b[39m compute_returns()\n",
      "\u001b[1;32m/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_returns\u001b[39m():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     index \u001b[39m=\u001b[39m clip_for_markout(etf_executions\u001b[39m.\u001b[39;49mresample(resample_freq, label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mright\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mlast(), max_markout\u001b[39m=\u001b[39;49mmax_markout)\u001b[39m.\u001b[39mindex\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     returns \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/petit/Documents/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#Y164sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m etfs:\n",
      "File \u001b[0;32m~/Documents/code/lobster-tools/notebooks/../lobster_tools/flow_decomposition.py:411\u001b[0m, in \u001b[0;36mclip_for_markout\u001b[0;34m(df, max_markout)\u001b[0m\n\u001b[1;32m    409\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(df\u001b[39m.\u001b[39mindex) \u001b[39m-\u001b[39m pd\u001b[39m.\u001b[39mTimedelta(max_markout)\n\u001b[1;32m    410\u001b[0m end \u001b[39m=\u001b[39m end\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 411\u001b[0m \u001b[39mreturn\u001b[39;00m clip_times(df, end\u001b[39m=\u001b[39mend)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clip_times' is not defined"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "def compute_returns():\n",
    "    index = clip_for_markout(etf_executions.resample(resample_freq, label=\"right\").last(), max_markout=max_markout).index\n",
    "\n",
    "    returns = {}\n",
    "    for ticker in etfs:\n",
    "        df = pd.DataFrame(index=index)\n",
    "        for markout in [\"0S\"] + markouts:\n",
    "            df[f\"_{markout}\"] = mids.loc[df.index + pd.Timedelta(markout), ticker].values\n",
    "\n",
    "        for markout in markouts:\n",
    "            df.eval(f\"return_{markout} = (_{markout} / _0S ) - 1\", inplace=True)\n",
    "\n",
    "        df[\"return_contemp\"] = mids[ticker].resample(\"5T\").first().pct_change()\n",
    "        df_returns = df.filter(regex=\"return\")\n",
    "        df_returns.columns = [column.replace(\"return_\", \"\") for column in df_returns.columns]\n",
    "        df_returns.columns = [(\"_\" + column if column[0].isdigit() else column) for column in df_returns.columns ]\n",
    "        returns[ticker] = df_returns\n",
    "    return returns\n",
    "\n",
    "returns = compute_returns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
