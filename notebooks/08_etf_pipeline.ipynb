{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETF Pipeline\n",
    "\n",
    "> ETF flow decompositions pipeline.\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp etf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "\n",
    "import click\n",
    "from arcticdb import Arctic, QueryBuilder\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from lobster_tools.config import MainConfig, Overrides, register_configs, get_config\n",
    "from lobster_tools.preprocessing import *\n",
    "from lobster_tools.querying import *\n",
    "from lobster_tools.flow_decomposition import *\n",
    "from lobster_tools.config import etf_to_equities\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import product\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "import json\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "register_configs()\n",
    "cfg = get_config(overrides=Overrides.full_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "directory_path = cfg.data_config.csv_files_path\n",
    "etfs = cfg.universe.etfs\n",
    "equities = cfg.universe.equities\n",
    "# fix this\n",
    "date_range = tuple(cfg.data_config.date_range)\n",
    "markouts = cfg.hyperparameters.markouts\n",
    "finest_resample = cfg.hyperparameters.finest_resample\n",
    "max_markout = cfg.hyperparameters.max_markout\n",
    "\n",
    "load: Literal[\"both\", \"messages\", \"book\"] = \"both\"\n",
    "clip_trading_hours = True\n",
    "add_ticker_column = True\n",
    "\n",
    "ticker = \"APA\"\n",
    "date_range = (\"2020-01-02\", \"2020-01-04\")\n",
    "date_range = \"2020-01-02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "data = Data(\n",
    "    directory_path=\"/nfs/home/nicolasp/home/data/tmp\",\n",
    "    ticker=\"COP\",\n",
    "    date_range=\"2020-01-03\",\n",
    "    aggregate_duplicates=False,\n",
    ")\n",
    "lobster = Lobster(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with initialize_config_module(version_base=None, config_module=\"lobster_tools.config\"):\n",
    "#     cfg = compose(overrides=[\"data_config=server\"])\n",
    "#     print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "Data(directory_path=directory_path, ticker=\"APA\", date_range=\"2020-01-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_data = Data(directory_path=directory_path,\n",
    "                   ticker=ticker,\n",
    "                   date_range=date_range,\n",
    "                   load=load,\n",
    "                   clip_trading_hours=clip_trading_hours,\n",
    "                   add_ticker_column=add_ticker_column)\n",
    "\n",
    "equity_lobsters = Lobster(equity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_data = [\n",
    "    Data(\n",
    "        directory_path=directory_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=load,\n",
    "        clip_trading_hours=clip_trading_hours,\n",
    "        add_ticker_column=add_ticker_column,\n",
    "    )\n",
    "    for ticker in equities\n",
    "]\n",
    "\n",
    "equity_lobsters = [Lobster(data) for data in equity_data]\n",
    "\n",
    "equity_executions = pd.concat(\n",
    "    [lobster.messages.pipe(get_executions) for lobster in equity_lobsters]\n",
    ")\n",
    "equity_executions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_data = [\n",
    "    Data(\n",
    "        directory_path=directory_path,\n",
    "        ticker=ticker,\n",
    "        date_range=date_range,\n",
    "        load=load,\n",
    "        clip_trading_hours=clip_trading_hours,\n",
    "        add_ticker_column=add_ticker_column,\n",
    "    )\n",
    "    for ticker in etfs\n",
    "]\n",
    "\n",
    "etf_lobsters = [Lobster(data) for data in etf_data]\n",
    "\n",
    "etf_executions = pd.concat(\n",
    "    [lobster.messages.pipe(get_executions) for lobster in etf_lobsters]\n",
    ")\n",
    "etf_executions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load with ArcticDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available tickers:\n",
      "['SLG', 'CSCO', 'HPE', 'PWR', 'AVB', 'CNC', 'NOW', 'ROP', 'XYL', 'AMGN', 'PXD', 'TROW', 'CB', 'AON', 'LB', 'PNR', 'SBAC', 'BAC', 'AMAT', 'ETR', 'SHW', 'CMS', 'WFC', 'LEN', 'PVH', 'VRSN', 'ZTS', 'PFE', 'XRX', 'CFG', 'HIG', 'MMC', 'MTD', 'FE', 'MLM', 'ZBH', 'XEC', 'AZO', 'SWK', 'CBOE', 'CTAS', 'FTNT', 'NSC', 'ICE', 'MKC', 'PSX', 'ABT', 'CDW', 'EQIX', 'FTV', 'HON', 'GD', 'PSA', 'VNO', 'XEL', 'KHC', 'ORCL', 'DGX', 'DE', 'GPC', 'NVR', 'INFO', 'FLIR', 'EBAY', 'CE', 'DG', 'LYB', 'MAS', 'ALB', 'NWSA', 'DD', 'BK', 'DLTR', 'PFG', 'CVS', 'COST', 'CI', 'HOG', 'IRM', 'MAR', 'OMC', 'UAA', 'WCG', 'HBAN', 'LKQ', 'WRK', 'RMD', 'MA', 'PRGO', 'AAP', 'MET', 'MXIM', 'PEP', 'MSCI', 'ADBE', 'ITW', 'KSS', 'STT', 'FRC', 'XOM', 'HCA', 'PLD', 'DRI', 'GLW', 'SPGI', 'EFX', 'MCI', 'BR', 'JCI', 'COP', 'FISV', 'HBI', 'GIS', 'CPRT', 'HPQ', 'RCL', 'APH', 'DHI', 'LUV', 'ANTM', 'JWN', 'ABC', 'VZ', 'NTRS', 'VTR', 'RE', 'KLAC', 'TMO', 'NDAQ', 'NWL', 'LDOS', 'TWTR', 'MCD', 'AEE', 'NI', 'MU', 'TGT', 'FCX', 'CCI', 'AIG', 'MAC', 'HAS', 'PG', 'PHM', 'PH', 'PPL', 'TXN', 'GWW', 'KEYS', 'NUE', 'GRMN', 'SPG', 'AMT', 'CINF', 'BWA', 'NVDA', 'PPG', 'SRE', 'COO', 'DOV', 'SWKS', 'TXT', 'CHRW', 'WYNN', 'JNJ', 'HP', 'CAH', 'KMI', 'JNPR', 'WY', 'FLS', 'FAST', 'GILD', 'ADS', 'AME', 'CLX', 'UNP', 'FOXA', 'MRK', 'DISCK', 'IBM', 'FTI', 'VFC', 'NCLH', 'CSX', 'LW', 'SBUX', 'HFC', 'INTC', 'ARNC', 'WHR', 'ANET', 'AAL', 'EXPD', 'DIS', 'RF', 'WRB', 'AMG', 'ARE', 'SYY', 'BLL', 'DFS', 'ESS', 'GM', 'KR', 'MOS', 'RL', 'SLB', 'NOV', 'MCHP', 'MNST', 'IPGP', 'DRE', 'JBHT', 'TEL', 'IFF', 'MTB', 'GOOGL', 'CF', 'PYPL', 'BDX', 'HRL', 'FLT', 'HSIC', 'GPN', 'RTN', 'KMX', 'SNA', 'OKE', 'GOOG', 'YUM', 'FANG', 'HRB', 'WLTW', 'DAL', 'EW', 'CME', 'SIVB', 'CMG', 'RJF', 'IR', 'KMB', 'DVA', 'DLR', 'LEG', 'UA', 'PGR', 'V', 'HII', 'PNW', 'TJX', 'WBA', 'ALL', 'FRT', 'PAYX', 'XRAY', 'PKI', 'AKAM', 'NFLX', 'INTU', 'NWS', 'PEG', 'INCY', 'ACN', 'GE', 'WEC', 'AOS', 'BF.B', 'AES', 'HLT', 'JKHY', 'NLSN', 'ODFL', 'CMI', 'DISH', 'STZ', 'ADM', 'NOC', 'BLK', 'DOW', 'ES', 'RHI', 'MHK', 'MSI', 'VAR', 'TDG', 'PBCT', 'BBY', 'SJM', 'EXR', 'EQR', 'FBHS', 'AIZ', 'BEN', 'TAP']\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "db_path = cfg.db.db_path\n",
    "\n",
    "conn = f'lmdb://{db_path}'\n",
    "arctic = Arctic(conn)\n",
    "library = \"NASDAQ\"\n",
    "arctic_library = arctic[library]\n",
    "print('available tickers:')\n",
    "print(arctic_library.list_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchVersionException",
     "evalue": "E_NO_SUCH_VERSION read_dataframe_version: version matching query 'latest' not found for symbol 'UDR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchVersionException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/nfs/home/nicolasp/home/code/lobster-tools/notebooks/08_etf_pipeline.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mdate_range((pd\u001b[39m.\u001b[39mTimestamp(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2016-01-04T09:29\u001b[39m\u001b[39m\"\u001b[39m), pd\u001b[39m.\u001b[39mTimestamp(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2016-01-06T16:01\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# q = q[q.event.isin(EventGroup.EXECUTIONS.value)]\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m arctic_library\u001b[39m.\u001b[39;49mread(ticker, query_builder\u001b[39m=\u001b[39;49mq, columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mevent\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39morder_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mprice\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdirection\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbid_price_1\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mask_price_1\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mdata\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brapid-01/nfs/home/nicolasp/home/code/lobster-tools/notebooks/08_etf_pipeline.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df\n",
      "File \u001b[0;32m~/anaconda3/envs/lob/lib/python3.11/site-packages/arcticdb/version_store/library.py:986\u001b[0m, in \u001b[0;36mLibrary.read\u001b[0;34m(self, symbol, as_of, date_range, columns, query_builder)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\n\u001b[1;32m    922\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    923\u001b[0m     symbol: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m     query_builder: Optional[QueryBuilder] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    928\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VersionedItem:\n\u001b[1;32m    929\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[39m    Read data for the named symbol.  Returns a VersionedItem object with a data and metadata element (as passed into\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[39m    write).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39m    2       7\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nvs\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    987\u001b[0m         symbol\u001b[39m=\u001b[39;49msymbol, as_of\u001b[39m=\u001b[39;49mas_of, date_range\u001b[39m=\u001b[39;49mdate_range, columns\u001b[39m=\u001b[39;49mcolumns, query_builder\u001b[39m=\u001b[39;49mquery_builder\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lob/lib/python3.11/site-packages/arcticdb/version_store/_store.py:1619\u001b[0m, in \u001b[0;36mNativeVersionStore.read\u001b[0;34m(self, symbol, as_of, date_range, row_range, columns, query_builder, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     query_builder \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mdate_range(date_range)\u001b[39m.\u001b[39mthen(query_builder)\n\u001b[1;32m   1616\u001b[0m version_query, read_options, read_query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_queries(\n\u001b[1;32m   1617\u001b[0m     as_of, date_range, row_range, columns, query_builder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m   1618\u001b[0m )\n\u001b[0;32m-> 1619\u001b[0m read_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_dataframe(symbol, version_query, read_query, read_options)\n\u001b[1;32m   1620\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_dataframe(read_result, read_query, query_builder)\n",
      "File \u001b[0;32m~/anaconda3/envs/lob/lib/python3.11/site-packages/arcticdb/version_store/_store.py:1686\u001b[0m, in \u001b[0;36mNativeVersionStore._read_dataframe\u001b[0;34m(self, symbol, version_query, read_query, read_options)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_dataframe\u001b[39m(\u001b[39mself\u001b[39m, symbol, version_query, read_query, read_options):\n\u001b[0;32m-> 1686\u001b[0m     \u001b[39mreturn\u001b[39;00m ReadResult(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mversion_store\u001b[39m.\u001b[39;49mread_dataframe_version(symbol, version_query, read_query, read_options))\n",
      "\u001b[0;31mNoSuchVersionException\u001b[0m: E_NO_SUCH_VERSION read_dataframe_version: version matching query 'latest' not found for symbol 'UDR'"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "ticker = \"UDR\"\n",
    "q = QueryBuilder()\n",
    "q = q.date_range((pd.Timestamp(f\"2016-01-04T09:29\"), pd.Timestamp(f\"2016-01-06T16:01\")))\n",
    "# q = q[q.event.isin(EventGroup.EXECUTIONS.value)]\n",
    "df = arctic_library.read(ticker, query_builder=q, columns=[\"event\", \"order_id\", \"size\", \"price\", \"direction\", \"bid_price_1\", \"ask_price_1\"]).data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>order_id</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>direction</th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-10 15:59:59.752373153</th>\n",
       "      <td>3</td>\n",
       "      <td>275468889</td>\n",
       "      <td>100</td>\n",
       "      <td>32.39</td>\n",
       "      <td>-1</td>\n",
       "      <td>32.38</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10 15:59:59.924996854</th>\n",
       "      <td>3</td>\n",
       "      <td>275930645</td>\n",
       "      <td>700</td>\n",
       "      <td>32.32</td>\n",
       "      <td>1</td>\n",
       "      <td>32.38</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10 15:59:59.924996854</th>\n",
       "      <td>1</td>\n",
       "      <td>276591509</td>\n",
       "      <td>700</td>\n",
       "      <td>32.33</td>\n",
       "      <td>1</td>\n",
       "      <td>32.38</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10 15:59:59.952231315</th>\n",
       "      <td>3</td>\n",
       "      <td>276507025</td>\n",
       "      <td>200</td>\n",
       "      <td>32.38</td>\n",
       "      <td>-1</td>\n",
       "      <td>32.38</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10 15:59:59.952248660</th>\n",
       "      <td>3</td>\n",
       "      <td>276507897</td>\n",
       "      <td>100</td>\n",
       "      <td>32.38</td>\n",
       "      <td>-1</td>\n",
       "      <td>32.38</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               event   order_id  size  price  direction  \\\n",
       "datetime                                                                  \n",
       "2020-01-10 15:59:59.752373153      3  275468889   100  32.39         -1   \n",
       "2020-01-10 15:59:59.924996854      3  275930645   700  32.32          1   \n",
       "2020-01-10 15:59:59.924996854      1  276591509   700  32.33          1   \n",
       "2020-01-10 15:59:59.952231315      3  276507025   200  32.38         -1   \n",
       "2020-01-10 15:59:59.952248660      3  276507897   100  32.38         -1   \n",
       "\n",
       "                               ask_price_1  bid_price_1  \n",
       "datetime                                                 \n",
       "2020-01-10 15:59:59.752373153        32.38        32.35  \n",
       "2020-01-10 15:59:59.924996854        32.38        32.35  \n",
       "2020-01-10 15:59:59.924996854        32.38        32.35  \n",
       "2020-01-10 15:59:59.952231315        32.38        32.35  \n",
       "2020-01-10 15:59:59.952248660        32.38        32.35  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval: false\n",
    "ticker = \"APA\"\n",
    "# q = QueryBuilder()\n",
    "# q = q.date_range((pd.Timestamp(f\"2020-01-07T09:29\"), pd.Timestamp(f\"2020-01-10T16:01\")))\n",
    "# q = q[q.event.isin(EventGroup.EXECUTIONS.value)]\n",
    "df = library.read(ticker, columns=[\"event\", \"order_id\", \"size\", \"price\", \"direction\", \"bid_price_1\", \"ask_price_1\"]).data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def get_data_from_arctic(ticker, date):\n",
    "    q = QueryBuilder()\n",
    "    q = q.date_range((pd.Timestamp(f\"{date}T09:29\"), pd.Timestamp(f\"{date}T16:01\")))\n",
    "    # get executions\n",
    "    q = q[q.event.isin(EventGroup.EXECUTIONS.value)]\n",
    "    df = library.read(ticker, query_builder=q, columns=[\"event\", \"order_id\", \"size\", \"price\", \"direction\", \"bid_price_1\", \"ask_price_1\"]).data\n",
    "    \n",
    "    # do assign here for now\n",
    "    df = df.assign(ticker=ticker)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def get_data_from_arctic_(ticker):\n",
    "    q = QueryBuilder()\n",
    "    q = q.date_range((pd.Timestamp(f\"2020-01-02T09:29\"), pd.Timestamp(f\"2020-01-03T16:01\")))\n",
    "    # get executions\n",
    "    q = q[q.event.isin(EventGroup.EXECUTIONS.value)]\n",
    "    df = library.read(ticker, query_builder=q, columns=[\"event\", \"order_id\", \"size\", \"price\", \"direction\", \"bid_price_1\", \"ask_price_1\"]).data\n",
    "    \n",
    "    # do assign here for now\n",
    "    df = df.assign(ticker=ticker)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "# equities=[\"APA\", \"BKR\", \"HAL\"]\n",
    "# equities=['APA', 'XOM', 'EOG', 'OXY', 'MPC', 'HES', 'BKR', 'KMI', 'PXD', 'PSX', 'HAL', 'DVN', 'OKE', 'CVX', 'FANG', 'VLO', 'WMB', 'COP', 'SLB']\n",
    "equities = [\n",
    "    \"HES\",\n",
    "    \"EOG\",\n",
    "    \"VLO\",\n",
    "    \"DVN\",\n",
    "    \"OXY\",\n",
    "    \"PXD\",\n",
    "    \"XOM\",\n",
    "    \"COP\",\n",
    "    \"WMB\",\n",
    "    \"HAL\",\n",
    "    \"PSX\",\n",
    "    \"CVX\",\n",
    "    \"OKE\",\n",
    "    \"BKR\",\n",
    "]\n",
    "etfs = [\"XLE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_executions = pd.concat(\n",
    "    [get_data_from_arctic_(ticker=ticker) for ticker in equities]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "equity_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions = pd.concat(\n",
    "    [get_data_from_arctic(ticker=ticker, date=\"2020-01-02\") for ticker in etfs]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions = pd.concat(\n",
    "    [get_data_from_arctic_(ticker=ticker) for ticker in etfs]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: pickle and load pickles.. looks like nbdev doesn't work with cell magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "%store etf_executions\n",
    "%store equity_executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell magic doesn't work with nbdev(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "ofi_all = ofi(etf_executions, resample_freq=\"5T\", suffix=\"all\")\n",
    "ofi_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "markout_times = markout_returns(ofi_all, markouts=markouts)\n",
    "markout_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "mids = etf_executions.eval(\"bid_price_1 + (ask_price_1 - bid_price_1) / 2\").resample(finest_resample, label=\"right\").last()\n",
    "mids = pd.DataFrame(mids, columns=etfs)\n",
    "# mids.resample(resample_freq, label=\"right\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "# markout_times = markout_returns(ofi_all, markouts=markouts)\n",
    "# mids = [resample_mid(lobster.book, resample_freq=finest_resample).rename(lobster.data.ticker) for lobster in etf_lobsters]\n",
    "# mids = pd.concat(mids, axis=1)\n",
    "# mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def compute_returns():\n",
    "    index = clip_for_markout(etf_executions.resample(resample_freq, label=\"right\").last(), max_markout=max_markout).index\n",
    "\n",
    "    returns = {}\n",
    "    for ticker in etfs:\n",
    "        df = pd.DataFrame(index=index)\n",
    "        print(df)\n",
    "        for markout in [\"0S\"] + markouts:\n",
    "            df[f\"_{markout}\"] = mids.loc[df.index + pd.Timedelta(markout), ticker].values\n",
    "\n",
    "        for markout in markouts:\n",
    "            df.eval(f\"return_{markout} = (_{markout} / _0S ) - 1\", inplace=True)\n",
    "\n",
    "        df[\"return_contemp\"] = mids[ticker].resample(\"5T\").first().pct_change()\n",
    "        df_returns = df.filter(regex=\"return\")\n",
    "        df_returns.columns = [column.replace(\"return_\", \"\") for column in df_returns.columns]\n",
    "        df_returns.columns = [(\"_\" + column if column[0].isdigit() else column) for column in df_returns.columns ]\n",
    "        # new addition\n",
    "        df_returns.fillna(0, inplace=True)\n",
    "        returns[ticker] = df_returns\n",
    "    return returns\n",
    "\n",
    "returns = compute_returns()\n",
    "returns[etfs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "returns[etfs[0]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def regression_table(\n",
    "    X: pd.DataFrame,  # covariates. in this case, OFI for a single ETF\n",
    "    y: pd.DataFrame,  # response variable. in this case, mid to mid returns at various markouts\n",
    "):\n",
    "    \"\"\"Compute X.len * y.len univariate regressions. For each column in X, regress against each one column of y.\"\"\"\n",
    "    X, y = restrict_common_index(X, y)\n",
    "    \n",
    "    regression_results = []\n",
    "\n",
    "    for x_col_name, y_col_name in product(X.columns, y.columns):\n",
    "        x_col = X[x_col_name].values.reshape(-1, 1)\n",
    "        y_col = y[y_col_name].values\n",
    "        \n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(x_col, y_col)\n",
    "\n",
    "        intercept = model.intercept_\n",
    "        coefficient = model.coef_[0]\n",
    "        r2 = model.score(x_col, y_col)\n",
    "\n",
    "        regression_results.append(\n",
    "            {\n",
    "                \"id\": x_col_name + \"_\" + y_col_name,\n",
    "                \"intercept\": intercept,\n",
    "                \"coefficient\": coefficient,\n",
    "                \"r2\": r2,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    regression_results_df = pd.DataFrame(regression_results)\n",
    "    regression_results_df.set_index(\"id\", inplace=True)\n",
    "    return regression_results_df\n",
    "\n",
    "regression_table(ofi_all, returns[etfs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "drop_all_neighbor_cols(etf_executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_neighbors = add_neighbors(etf_executions=etf_executions, equity_executions=equity_executions, tolerance=tolerances)\n",
    "etf_executions_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def compute_neighbor_statistics(etf_executions_neighbors: pd.DataFrame):\n",
    "    neighbor_statistics = etf_executions_neighbors.filter(regex=\"^_\").notna().sum() / len(etf_executions_neighbors)\n",
    "    return neighbor_statistics\n",
    "\n",
    "neighbor_statistics = compute_neighbor_statistics(etf_executions_neighbors)\n",
    "# pd.DataFrame({'has_neighbor':neighbor_statistics}).style.format(\"{:.2%}\")\n",
    "pd.DataFrame({'has_neighbor':neighbor_statistics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_features = append_features(etf_executions=etf_executions_neighbors, equity_executions=equity_executions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_features[\"_500us_num_trades\"] = etf_executions_features._500us_num_trades_os_af + etf_executions_features._500us_num_trades_os_bf + etf_executions_features._500us_num_trades_ss_af + etf_executions_features._500us_num_trades_ss_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_features._500us_num_trades.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "val_counts = etf_executions_features.value_counts(subset=\"_500us_num_trades\")\n",
    "val_counts.where(val_counts > 100).dropna().index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "ENOUGH_DATA = 7\n",
    "etf_executions_features.query(f\"_500us_num_trades <= {ENOUGH_DATA}\")\n",
    "\n",
    "CLOSE_PRICE = ( etf_executions_features.query(\"direction == 1\").iloc[-1].price + etf_executions_features.query(\"direction == -1\").iloc[-1].price ) / 2\n",
    "print(CLOSE_PRICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_features_no_auc = etf_executions_features[etf_executions_features.event.isin([4,5])]\n",
    "etf_executions_features_no_auc = etf_executions_features_no_auc.query(f\"_500us_num_trades <= {ENOUGH_DATA}\").assign(pnl_to_close = lambda df_: ( CLOSE_PRICE - df_.price ) / df_.price * 1e4 * df_.direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "etf_executions_features_no_auc = etf_executions_features_no_auc.assign(hit_ratio = lambda df_: ((df_.pnl_to_close) > 0 ))\n",
    "summary_statistics = etf_executions_features_no_auc.groupby(by=\"_500us_num_trades\").agg(ppt_mean=(\"pnl_to_close\",\"mean\"),ppt_std=(\"pnl_to_close\",\"std\"), hit_raio=(\"hit_ratio\",\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "import matplotlib.pyplot as plt\n",
    "for col in summary_statistics:\n",
    "    summary_statistics[col].plot(title=col, kind=\"bar\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "df = etf_executions_features_no_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "closing_prices = df.resample('D').transform('last').price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "df[\"closing_price\"] = closing_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "df.eval(\"pnl_to_close = (closing_price - price) * 1e4 * direction\", inplace=True)\n",
    "df.eval(\"hit_ratio = (pnl_to_close > 0)\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "summary_statistics = df.groupby(by=\"_500us_num_trades\").agg(ppt_mean=(\"pnl_to_close\",\"mean\"),ppt_std=(\"pnl_to_close\",\"std\"), hit_ratio=(\"hit_ratio\",\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "import matplotlib.pyplot as plt\n",
    "for col in summary_statistics:\n",
    "    summary_statistics[col].plot(title=col, kind=\"bar\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "%store etf_executions_neighbors\n",
    "%store etf_executions_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_executions_features = marginalise(etf_executions_features, over='same_sign/opposite_sign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_executions_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_executions_features[\"_500us_num_trades\"] = etf_executions_features._500us_num_trades_os_af + etf_executions_features._500us_num_trades_os_bf + etf_executions_features._500us_num_trades_ss_af + etf_executions_features._500us_num_trades_ss_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etf_execution_features.filter(regex=\"^_\").hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy way without query builder\n",
    "# date_range = [datetime.date(year=2020, month=1, day=2), datetime.date(year=2020, month=1, day=3)]\n",
    "# df = library.read(ticker, date_range=date_range).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
