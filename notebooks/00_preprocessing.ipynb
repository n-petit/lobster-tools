{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ðŸ—‚\n",
    "\n",
    "> Preprocessing of csv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import enum\n",
    "import glob\n",
    "from typing import Optional, Literal, get_args\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | export\n",
    "@enum.unique\n",
    "class Event(enum.Enum):\n",
    "    \"A class to represent the event type of a LOBSTER message.\"\n",
    "    UNKNOWN = 0\n",
    "    SUBMISSION = 1\n",
    "    CANCELLATION = 2\n",
    "    DELETION = 3\n",
    "    EXECUTION = 4\n",
    "    HIDDEN_EXECUTION = 5\n",
    "    CROSS_TRADE = 6\n",
    "    OTHER = 8\n",
    "    TRADING_HALT = 9\n",
    "    RESUME_QUOTE = 10\n",
    "    TRADING_RESUME = 11\n",
    "\n",
    "\n",
    "@enum.unique\n",
    "class EventGroup(enum.Enum):\n",
    "    EXECUTIONS = [Event.EXECUTION.value, Event.HIDDEN_EXECUTION.value]\n",
    "    HALTS = [\n",
    "        Event.TRADING_HALT.value,\n",
    "        Event.RESUME_QUOTE.value,\n",
    "        Event.TRADING_RESUME.value,\n",
    "    ]\n",
    "    CANCELLATIONS = [Event.CANCELLATION.value, Event.DELETION.value]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The event column in the lobster data encodes the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNKNOWN': 0,\n",
       " 'SUBMISSION': 1,\n",
       " 'CANCELLATION': 2,\n",
       " 'DELETION': 3,\n",
       " 'EXECUTION': 4,\n",
       " 'HIDDEN_EXECUTION': 5,\n",
       " 'CROSS_TRADE': 6,\n",
       " 'OTHER': 8,\n",
       " 'TRADING_HALT': 9,\n",
       " 'RESUME_QUOTE': 10,\n",
       " 'TRADING_RESUME': 11}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "{e.name: e.value for e in Event}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Here, trading halts are split into three categories: trading halt, resume quote and trading resume. To access all three types of trading halt events, use `EventGroup.TRADING_HALTS`.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access common groups of events, an `EventGroup` is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CANCELLATIONS': [2, 3],\n",
      " 'EXECUTIONS': [4, 5],\n",
      " 'HALTS': [9, 10, 11]}\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "pprint({e.name: e.value for e in EventGroup}, width=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | export\n",
    "\n",
    "\n",
    "@enum.unique\n",
    "class Direction(enum.Enum):\n",
    "    BUY = 1\n",
    "    SELL = -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv data is assumed to be stored roughly as follows. There should be one folder per ticker, with underscores separating the ticker name, start date, end date and number of levels. Each individual csv filename should also end with the number of levels. All dates should be listed as %YYYY-%MM-%DD convention."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "csv_lobster_data\n",
    "â”œâ”€â”€ AAPL_2016-06-21_2016-06-21_10\n",
    "â”‚Â Â  â”œâ”€â”€ AAPL_2012-06-21_34200000_57600000_message_10.csv\n",
    "â”‚Â Â  â”œâ”€â”€ AAPL_2012-06-21_34200000_57600000_orderbook_10.csv\n",
    "â”‚Â Â  â”œâ”€â”€ AAPL_2012-06-22_34200000_57600000_message_10.csv\n",
    "â”‚Â Â  â””â”€â”€ AAPL_2012-06-22_34200000_57600000_orderbook_10.csv\n",
    "â”œâ”€â”€ GOOG_2016-06-21_2016-06-22_10\n",
    "â”‚Â Â  â”œâ”€â”€ GOOG_2012-06-21_34200000_57600000_message_10.csv\n",
    "â”‚Â Â  â”œâ”€â”€ GOOG_2012-06-21_34200000_57600000_orderbook_10.csv\n",
    "â”‚Â Â  â”œâ”€â”€ GOOG_2012-06-22_34200000_57600000_message_10.csv\n",
    "â”‚Â Â  â””â”€â”€ GOOG_2012-06-22_34200000_57600000_orderbook_10.csv\n",
    "â””â”€â”€ LOBSTER_SampleFiles_ReadMe.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Data` object stores information about the data to be loaded, as well as specifying which preprocessing options are to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 'equity', 'etf')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "LoadType = Literal[\"both\", \"messages\", \"book\"]\n",
    "TickerTypes = Literal[None, \"equity\", \"etf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "# | code-fold: true\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Data:\n",
    "    directory_path: str = \"/home/petit/Documents/data/lobster/csv\"  # path to data\n",
    "    ticker: str = \"AAPL\"\n",
    "    date_range: Optional[str | tuple[str, str]] = None\n",
    "    levels: Optional[int] = None\n",
    "    nrows: Optional[int] = None\n",
    "    load: LoadType = \"messages\"\n",
    "    add_ticker: bool = True\n",
    "    ticker_type: TickerTypes = None\n",
    "    clip_trading_hours: bool = True\n",
    "    aggregate_duplicates: bool = True\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        assert self.load in get_args(LoadType)\n",
    "        assert self.ticker_type in get_args(TickerTypes)\n",
    "\n",
    "        # ticker path\n",
    "        tickers = glob.glob(f\"{self.directory_path}/*\")\n",
    "        ticker_path = [t for t in tickers if self.ticker in t]\n",
    "        assert len(ticker_path) == 1\n",
    "        self.ticker_path = ticker_path[0]\n",
    "\n",
    "        # levels\n",
    "        if not self.levels:\n",
    "            self.levels = int(self.ticker_path.split(\"_\")[-1])\n",
    "            assert self.levels >= 1\n",
    "\n",
    "        # infer date range from ticker folder name\n",
    "        if not self.date_range:\n",
    "            self.date_range = tuple(re.findall(pattern=r\"\\d\\d\\d\\d-\\d\\d-\\d\\d\", string=self.ticker_path))\n",
    "            assert len(self.date_range) == 2\n",
    "\n",
    "        # book and message paths\n",
    "        tickers = glob.glob(f\"{self.ticker_path}/*\")\n",
    "        tickers_end = list(map(os.path.basename, tickers))\n",
    "\n",
    "        if isinstance(self.date_range, tuple):\n",
    "            # get all dates in folder\n",
    "            dates = set([re.findall(pattern=r\"\\d\\d\\d\\d-\\d\\d-\\d\\d\", string=file)[0] for file in tickers_end])\n",
    "            # filter for dates within specified range\n",
    "            dates = sorted(\n",
    "                list(\n",
    "                    filter(\n",
    "                        lambda date: self.date_range[0] <= date <= self.date_range[1],\n",
    "                        dates,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.dates = dates\n",
    "            self.date_range = (min(self.dates), max(self.dates))\n",
    "\n",
    "        elif isinstance(self.date_range, str):\n",
    "            self.dates, self.date_range = [self.date_range], (\n",
    "                self.date_range,\n",
    "                self.date_range,\n",
    "            )\n",
    "\n",
    "        # messages and book filepath dictionaries\n",
    "        def _create_date_to_path_dict(keyword: str) -> dict:\n",
    "            filter_keyword_tickers = list(filter(lambda x: keyword in x, tickers_end))\n",
    "            date_path_dict = {}\n",
    "            for date in self.dates:\n",
    "                filter_date_tickers = list(filter(lambda x: date in x, filter_keyword_tickers))\n",
    "                assert len(filter_date_tickers) == 1\n",
    "                date_path_dict[date] = os.path.join(self.ticker_path, filter_date_tickers[0])\n",
    "            return date_path_dict\n",
    "\n",
    "        self.book_paths = _create_date_to_path_dict(\"book\")\n",
    "        self.messages_paths = _create_date_to_path_dict(\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | export\n",
    "def aggregate_duplicates_(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    subset = list(df.columns)\n",
    "    subset.remove(\"size\")\n",
    "    subset.insert(0, \"datetime\")\n",
    "\n",
    "    duplicates_index = df.reset_index().duplicated(subset=subset, keep=False).values\n",
    "    duplicates = df[duplicates_index]\n",
    "    no_duplicates = df[~duplicates_index]\n",
    "\n",
    "    assert no_duplicates.shape[0] + duplicates.shape[0] == df.shape[0]\n",
    "\n",
    "    aggregated_duplicates = duplicates.groupby(by=[duplicates.index, \"direction\"]).agg({\"size\": \"sum\"})\n",
    "    aggregated_duplicates = pd.merge(duplicates, aggregated_duplicates, on=\"datetime\", suffixes=(\"_original\", \"_agg\"))\n",
    "    aggregated_duplicates.drop(columns=[\"size_original\"], inplace=True)\n",
    "    aggregated_duplicates.rename(columns={\"size_agg\": \"size\"}, inplace=True)\n",
    "    aggregated_duplicates.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "    df = pd.concat([no_duplicates, aggregated_duplicates])\n",
    "    df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Lobster` loads the csv data into its `messages` and `book` attributes. The data to be loaded is passed in as a `Data` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "# | code-fold: true\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Lobster:\n",
    "    \"Lobster data class for a single symbol of Lobster data.\"\n",
    "    data: Data = Data()\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.data.load in [\"messages\", \"both\"]:\n",
    "            dfs = []\n",
    "            for date, filepath in self.data.messages_paths.items():\n",
    "                # load messages\n",
    "                df = pd.read_csv(\n",
    "                    filepath,\n",
    "                    header=None,\n",
    "                    nrows=self.data.nrows,\n",
    "                    usecols=list(range(6)),\n",
    "                    names=[\"time\", \"event\", \"order_id\", \"size\", \"price\", \"direction\"],\n",
    "                    index_col=False,\n",
    "                    dtype={\n",
    "                        \"time\": \"float64\",\n",
    "                        \"event\": \"uint8\",\n",
    "                        \"price\": \"int64\",\n",
    "                        \"direction\": \"int8\",\n",
    "                        \"order_id\": \"uint32\",\n",
    "                        \"size\": \"uint64\",\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                # set index as datetime\n",
    "                df[\"datetime\"] = pd.to_datetime(date, format=\"%Y-%m-%d\") + df.time.apply(lambda x: pd.to_timedelta(x, unit=\"s\"))\n",
    "                df.set_index(\"datetime\", drop=True, inplace=True)\n",
    "                df.drop(columns=\"time\", inplace=True)\n",
    "                dfs.append(df)\n",
    "            df = pd.concat(dfs)\n",
    "\n",
    "            # use 0 as NaN for price, size and direction\n",
    "            assert df.loc[df.event.eq(Event.TRADING_HALT.value), \"direction\"].eq(-1).all()\n",
    "            df.loc[df.event.eq(Event.TRADING_HALT.value), \"direction\"] = 0\n",
    "\n",
    "            # process trading halts\n",
    "            def _trading_halt_type(price):\n",
    "                return {\n",
    "                    -1: Event.TRADING_HALT.value,\n",
    "                    0: Event.RESUME_QUOTE.value,\n",
    "                    1: Event.TRADING_RESUME.value,\n",
    "                }[price]\n",
    "\n",
    "            df.loc[df.event.eq(Event.TRADING_HALT.value), \"event\"] = df.loc[df.event.eq(Event.TRADING_HALT.value), \"price\"].apply(\n",
    "                lambda x: _trading_halt_type(x)\n",
    "            )\n",
    "\n",
    "            df.loc[\n",
    "                df.event.isin(EventGroup.HALTS.value),\n",
    "                [\"order_id\", \"size\", \"price\"],\n",
    "            ] = [\n",
    "                0,\n",
    "                0,\n",
    "                np.nan,\n",
    "            ]\n",
    "\n",
    "            # set price in dollars\n",
    "            df.price = df.price.apply(lambda x: x / 10_000).astype(\"float64\")\n",
    "\n",
    "            if self.data.add_ticker:\n",
    "                df = df.assign(ticker=self.data.ticker).astype({\"ticker\": \"category\"})\n",
    "\n",
    "            if self.data.ticker_type:\n",
    "                assert self.data.ticker_type in [\n",
    "                    \"equity\",\n",
    "                    \"etf\",\n",
    "                ], \"ticker_type must be either `equity` or `etf`\"\n",
    "                df = df.assign(ticker_type=self.data.ticker_type).astype(\n",
    "                    dtype={\"ticker_type\": pd.CategoricalDtype(categories=[\"equity\", \"etf\"])}\n",
    "                )\n",
    "\n",
    "            self.messages = df\n",
    "\n",
    "        if self.data.load in [\"book\", \"both\"]:\n",
    "            col_names = []\n",
    "            for level in range(1, self.data.levels + 1):\n",
    "                for col_type in [\"ask_price\", \"ask_size\", \"bid_price\", \"bid_size\"]:\n",
    "                    col_name = f\"{col_type}_{level}\"\n",
    "                    col_names.append(col_name)\n",
    "\n",
    "            # for now just use float64\n",
    "            # col_dtypes = {\n",
    "            #     col_name: pd.Int64Dtype() if (\"size\" in col_name) else \"float\"\n",
    "            #     for col_name in col_names\n",
    "            # }\n",
    "\n",
    "            dfs = []\n",
    "            for filename in self.data.book_paths.values():\n",
    "                df = pd.read_csv(\n",
    "                    filename,\n",
    "                    header=None,\n",
    "                    nrows=self.data.nrows,\n",
    "                    usecols=list(range(4 * self.data.levels)),\n",
    "                    names=col_names,\n",
    "                    dtype=\"float64\",\n",
    "                    na_values=[-9999999999, 9999999999, 0],\n",
    "                )\n",
    "\n",
    "                dfs.append(df)\n",
    "            df = pd.concat(dfs)\n",
    "            \n",
    "            df.set_index(self.messages.index, inplace=True, drop=True)\n",
    "\n",
    "            price_cols = df.columns.str.contains(\"price\")\n",
    "            df.loc[:, price_cols] = df.loc[:, price_cols].apply(lambda x: x / 10_000)\n",
    "\n",
    "            self.book = df\n",
    "\n",
    "        # data cleaning on messages done now, as book infers times from messages file\n",
    "        # aggregate duplicates \n",
    "        if self.data.aggregate_duplicates:\n",
    "            self.messages = aggregate_duplicates_(self.messages)\n",
    "\n",
    "        # clip messages to trading hours (from 9:30 to 4:30)\n",
    "        if self.data.clip_trading_hours:\n",
    "            df = df.iloc[(df.index.time >= datetime.time(9, 30)) & (df.index.time < datetime.time(16, 30))]\n",
    "\n",
    "            \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Lobster data for ticker: {self.data.ticker} for date range: {self.data.date_range[0]} to {self.data.date_range[1]}.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_lobster` is a simple function which returns a `Lobster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def load_lobster(**kwargs):\n",
    "    \"\"\"Load `Lobster` object from csv data.\"\"\"\n",
    "    data = Data(**kwargs)\n",
    "    lobster = Lobster(data)\n",
    "\n",
    "    return lobster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overwrite defaults `functools.partial` can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: true\n",
    "my_load_lobster = partial(load_lobster, directory_path=\"/my/path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "load_lobster = partial(load_lobster, directory_path=\"/home/petit/Documents/data/csv_lobster_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>order_id</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>direction</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ticker_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.004241176</th>\n",
       "      <td>1</td>\n",
       "      <td>16113575</td>\n",
       "      <td>18</td>\n",
       "      <td>585.33</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>equity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.004260640</th>\n",
       "      <td>1</td>\n",
       "      <td>16113584</td>\n",
       "      <td>18</td>\n",
       "      <td>585.32</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>equity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.004447484</th>\n",
       "      <td>1</td>\n",
       "      <td>16113594</td>\n",
       "      <td>18</td>\n",
       "      <td>585.31</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>equity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.025551909</th>\n",
       "      <td>1</td>\n",
       "      <td>16120456</td>\n",
       "      <td>18</td>\n",
       "      <td>585.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>equity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.025579546</th>\n",
       "      <td>1</td>\n",
       "      <td>16120480</td>\n",
       "      <td>18</td>\n",
       "      <td>585.92</td>\n",
       "      <td>-1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>equity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               event  order_id  size   price  direction  \\\n",
       "datetime                                                                  \n",
       "2012-06-21 09:30:00.004241176      1  16113575    18  585.33          1   \n",
       "2012-06-21 09:30:00.004260640      1  16113584    18  585.32          1   \n",
       "2012-06-21 09:30:00.004447484      1  16113594    18  585.31          1   \n",
       "2012-06-21 09:30:00.025551909      1  16120456    18  585.91         -1   \n",
       "2012-06-21 09:30:00.025579546      1  16120480    18  585.92         -1   \n",
       "\n",
       "                              ticker ticker_type  \n",
       "datetime                                          \n",
       "2012-06-21 09:30:00.004241176   AAPL      equity  \n",
       "2012-06-21 09:30:00.004260640   AAPL      equity  \n",
       "2012-06-21 09:30:00.004447484   AAPL      equity  \n",
       "2012-06-21 09:30:00.025551909   AAPL      equity  \n",
       "2012-06-21 09:30:00.025579546   AAPL      equity  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lobster = load_lobster(ticker=\"AAPL\", date_range=\"2012-06-21\", ticker_type=\"equity\")\n",
    "lobster.messages.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
